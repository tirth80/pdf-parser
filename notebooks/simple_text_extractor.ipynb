{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd1ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def extract_all_tables(pdf_path, output_dir, page_num=0, settings=None):\n",
    "    \"\"\"\n",
    "    Extracts all tables from a PDF page using pdfplumber and exports each to a CSV file.\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        output_dir (str): Directory to save CSV files.\n",
    "        page_num (int): Page number to extract tables from (0-indexed).\n",
    "        settings (dict): pdfplumber table extraction settings.\n",
    "    \"\"\"\n",
    "    if settings is None:\n",
    "        settings = {\n",
    "            \"vertical_strategy\": \"lines\",\n",
    "            \"horizontal_strategy\": \"lines\",\n",
    "            \"snap_tolerance\": 7,\n",
    "            \"join_tolerance\": 7,\n",
    "            \"edge_min_length\": 30,\n",
    "            \"text_x_tolerance\": 2,\n",
    "            \"text_y_tolerance\": 7,\n",
    "            \"intersection_tolerance\": 5,\n",
    "        }\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[page_num]\n",
    "        tables = page.extract_tables(settings)\n",
    "        for idx, table in enumerate(tables):\n",
    "            if not table or not table[0]:\n",
    "                continue\n",
    "            df = pd.DataFrame(table[1:], columns=table[0]) if len(table) > 1 else pd.DataFrame(table)\n",
    "            csv_path = os.path.join(output_dir, f\"table_{idx+1}.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\"Exported table {idx+1} to {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a1d91b",
   "metadata": {},
   "source": [
    "# Simple Text Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a63d8c",
   "metadata": {},
   "source": [
    "We are now going to build a simple text extractor for our PDF Parser so that our layout model (LayoutLMv3) and make sense of it from an input perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e44620",
   "metadata": {},
   "source": [
    "Here is our strategy:\n",
    "\n",
    "(From the Data_load):\n",
    "\n",
    "- Fetch the 10K filings from `SEC-EDGAR` library and `SEC-API` to generate raw data as txt to convert it to PDFs.\n",
    "\n",
    "(In this file):\n",
    "\n",
    "- Use `pdfplumber` library for thorough text extraction and `Tesseract` library for the OCR fallback. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e9b62",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207d7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from dataclasses import dataclass, asdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef5fba",
   "metadata": {},
   "source": [
    "## PDF Processing Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dafdeb1",
   "metadata": {},
   "source": [
    "- We begin by iterating through the documents in `data/raw`.\n",
    "- We also provide folder paths for the raw data and parsed data, implement checks using os if there are no directories available at the designated paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04ed259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "raw_pdf_dir = \"../data/raw/MSFT/10-K/PDFs\"\n",
    "parsed_output_dir = \"../data/parsed/MSFT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7fe1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(parsed_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd943d",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0a6b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WordBox:\n",
    "    \"\"\"Data class for word box information with comprehensive positioning data\"\"\"\n",
    "    text: str\n",
    "    x0: float\n",
    "    y0: float\n",
    "    x1: float\n",
    "    y1: float\n",
    "    width: float\n",
    "    height: float\n",
    "    fontname: Optional[str] = None\n",
    "    fontsize: Optional[float] = None\n",
    "    fontcolor: Optional[str] = None\n",
    "    confidence: Optional[float] = None\n",
    "    page_number: int = 0\n",
    "    word_index: int = 0\n",
    "    doctop: Optional[float] = None  # Document-level top position (page offset)\n",
    "    upright: Optional[bool] = None  # Text orientation (True = normal, False = rotated)\n",
    "    top: Optional[float] = None     # Page-relative top position\n",
    "    bottom: Optional[float] = None  # Page-relative bottom position\n",
    "    left: Optional[float] = None    # Page-relative left position  \n",
    "    right: Optional[float] = None   # Page-relative right position\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return asdict(self)\n",
    "    \n",
    "    @property\n",
    "    def center_x(self):\n",
    "        return (self.x0 + self.x1) / 2\n",
    "    \n",
    "    @property\n",
    "    def center_y(self):\n",
    "        return (self.y0 + self.y1) / 2\n",
    "    \n",
    "    @property\n",
    "    def area(self):\n",
    "        return self.width * self.height\n",
    "    \n",
    "    @property\n",
    "    def is_rotated(self):\n",
    "        \"\"\"Check if text is rotated (not upright)\"\"\"\n",
    "        return self.upright is False\n",
    "    \n",
    "    @property\n",
    "    def document_position(self):\n",
    "        \"\"\"Get document-level position including page offset\"\"\"\n",
    "        if self.doctop is not None:\n",
    "            return {\n",
    "                'document_top': self.doctop,\n",
    "                'page_relative_top': self.top,\n",
    "                'page_number': self.page_number\n",
    "            }\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b93717",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PageLayout:\n",
    "    \"\"\"Data class for page layout information with comprehensive analysis\"\"\"\n",
    "    page_number: int\n",
    "    page_width: float\n",
    "    page_height: float\n",
    "    word_boxes: List[WordBox]\n",
    "    text_blocks: List[Dict]\n",
    "    reading_order: List[int]\n",
    "    layout_analysis: Dict\n",
    "    \n",
    "    def to_dict(self):\n",
    "        \"\"\"Convert to dictionary for JSON serialization\"\"\"\n",
    "        return {\n",
    "            'page_number': self.page_number,\n",
    "            'page_width': self.page_width,\n",
    "            'page_height': self.page_height,\n",
    "            'word_boxes': [box.to_dict() for box in self.word_boxes],\n",
    "            'text_blocks': self.text_blocks,\n",
    "            'reading_order': self.reading_order,\n",
    "            'layout_analysis': self.layout_analysis\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def total_words(self):\n",
    "        \"\"\"Total number of words on the page\"\"\"\n",
    "        return len(self.word_boxes)\n",
    "    \n",
    "    @property\n",
    "    def text_density(self):\n",
    "        \"\"\"Text density as percentage of page area covered by text\"\"\"\n",
    "        if not self.word_boxes:\n",
    "            return 0.0\n",
    "        \n",
    "        total_text_area = sum(box.area for box in self.word_boxes)\n",
    "        page_area = self.page_width * self.page_height\n",
    "        return (total_text_area / page_area) * 100 if page_area > 0 else 0.0\n",
    "    \n",
    "    @property\n",
    "    def average_font_size(self):\n",
    "        \"\"\"Average font size across all words\"\"\"\n",
    "        font_sizes = [box.fontsize for box in self.word_boxes if box.fontsize is not None]\n",
    "        return np.mean(font_sizes) if font_sizes else 0.0\n",
    "    \n",
    "    @property\n",
    "    def layout_type(self):\n",
    "        \"\"\"Get the classified layout type\"\"\"\n",
    "        return self.layout_analysis.get('layout_type', 'unknown')\n",
    "    \n",
    "    @property\n",
    "    def estimated_columns(self):\n",
    "        \"\"\"Get the estimated number of columns\"\"\"\n",
    "        return self.layout_analysis.get('columns', 1)\n",
    "    \n",
    "    def get_words_by_column(self, column_index):\n",
    "        \"\"\"Get words belonging to a specific column\"\"\"\n",
    "        if self.estimated_columns <= 1:\n",
    "            return self.word_boxes\n",
    "        \n",
    "        column_width = self.page_width / self.estimated_columns\n",
    "        column_start = column_index * column_width\n",
    "        column_end = (column_index + 1) * column_width\n",
    "        \n",
    "        return [box for box in self.word_boxes \n",
    "                if column_start <= box.center_x < column_end]\n",
    "    \n",
    "    def get_words_by_line(self, line_tolerance=10):\n",
    "        \"\"\"Group words into lines based on Y-coordinate\"\"\"\n",
    "        if not self.word_boxes:\n",
    "            return []\n",
    "        \n",
    "        lines = []\n",
    "        current_line = []\n",
    "        \n",
    "        for box in sorted(self.word_boxes, key=lambda b: b.y0):\n",
    "            if not current_line or not any(abs(box.y0 - line_box.y0) < line_tolerance for line_box in current_line):\n",
    "                if current_line:\n",
    "                    lines.append(sorted(current_line, key=lambda b: b.x0))\n",
    "                current_line = [box]\n",
    "            else:\n",
    "                current_line.append(box)\n",
    "        \n",
    "        if current_line:\n",
    "            lines.append(sorted(current_line, key=lambda b: b.x0))\n",
    "        \n",
    "        return lines\n",
    "    \n",
    "    def get_rotated_words(self):\n",
    "        \"\"\"Get all rotated words on the page\"\"\"\n",
    "        return [box for box in self.word_boxes if box.is_rotated]\n",
    "    \n",
    "    def get_high_confidence_words(self, min_confidence=80):\n",
    "        \"\"\"Get words with confidence above threshold (for OCR results)\"\"\"\n",
    "        return [box for box in self.word_boxes \n",
    "                if box.confidence is not None and box.confidence >= min_confidence]\n",
    "    \n",
    "    def analyze_text_flow(self):\n",
    "        \"\"\"Analyze the text flow pattern on the page\"\"\"\n",
    "        if not self.word_boxes:\n",
    "            return {'flow_type': 'empty', 'flow_score': 0}\n",
    "        \n",
    "        # Analyze reading order consistency\n",
    "        reading_order_boxes = [self.word_boxes[i] for i in self.reading_order if i < len(self.word_boxes)]\n",
    "        \n",
    "        # Check if reading order follows logical flow\n",
    "        flow_violations = 0\n",
    "        for i in range(len(reading_order_boxes) - 1):\n",
    "            current = reading_order_boxes[i]\n",
    "            next_box = reading_order_boxes[i + 1]\n",
    "            \n",
    "            # Check for major violations (next word is significantly above or to the right)\n",
    "            if next_box.y0 < current.y0 - 20:  # Next word is much higher\n",
    "                flow_violations += 1\n",
    "            elif next_box.x0 > current.x1 + 100:  # Next word is far to the right\n",
    "                flow_violations += 1\n",
    "        \n",
    "        flow_score = max(0, 100 - (flow_violations / len(reading_order_boxes)) * 100)\n",
    "        \n",
    "        if flow_score > 90:\n",
    "            flow_type = 'excellent'\n",
    "        elif flow_score > 75:\n",
    "            flow_type = 'good'\n",
    "        elif flow_score > 50:\n",
    "            flow_type = 'fair'\n",
    "        else:\n",
    "            flow_type = 'poor'\n",
    "        \n",
    "        return {\n",
    "            'flow_type': flow_type,\n",
    "            'flow_score': flow_score,\n",
    "            'violations': flow_violations,\n",
    "            'total_transitions': len(reading_order_boxes) - 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe1698",
   "metadata": {},
   "source": [
    "### Remaining Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1155308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_pdfs():\n",
    "    \"\"\"Main function to process all MSFT 10-K PDFs with word box extraction and layout analysis\"\"\"\n",
    "    \n",
    "    # Get all PDF files\n",
    "    pdf_files = glob.glob(os.path.join(raw_pdf_dir, \"*.pdf\"))\n",
    "    print(f\"🔍 Found {len(pdf_files)} PDF files to process\")\n",
    "    \n",
    "    processing_stats = {\n",
    "        'total_files': len(pdf_files),\n",
    "        'processed_files': 0,\n",
    "        'failed_files': 0,\n",
    "        'total_pages': 0,\n",
    "        'total_word_boxes': 0,\n",
    "        'pdfplumber_pages': 0,\n",
    "        'ocr_pages': 0,\n",
    "        'poor_quality_pages': 0\n",
    "    }\n",
    "    \n",
    "    for pdf_path in pdf_files:\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        year = filename.split('_')[2][:4]\n",
    "        \n",
    "        print(f\"\\n📄 Processing: {filename}\")\n",
    "        print(f\"📅 Year: {year}\")\n",
    "        \n",
    "        # Create year-specific output directory\n",
    "        year_output_dir = os.path.join(parsed_output_dir, year)\n",
    "        os.makedirs(year_output_dir, exist_ok=True)\n",
    "        \n",
    "        table_settings = {\n",
    "            \"vertical_strategy\": \"lines\",\n",
    "            \"horizontal_strategy\": \"lines\",\n",
    "            \"snap_x_tolerance\": 10,\n",
    "            \"snap_y_tolerance\": 10,\n",
    "            \"join_tolerance\": 3,\n",
    "            \"edge_min_length\": 3,\n",
    "            \"min_words_vertical\": 3,\n",
    "            \"min_words_horizontal\": 1,\n",
    "            \"intersection_tolerance\": 3,\n",
    "            \"text_tolerance\": 3,\n",
    "            \"text_x_tolerance\": 3,\n",
    "            \"text_y_tolerance\": 3\n",
    "        }\n",
    "        \n",
    "        # Process the PDF\n",
    "        file_stats = process_single_pdf(pdf_path, year_output_dir, filename, table_settings)\n",
    "        \n",
    "        # Update overall statistics with safe key access\n",
    "        processing_stats['processed_files'] += 1\n",
    "        processing_stats['total_pages'] += file_stats.get('total_pages', 0)\n",
    "        processing_stats['total_word_boxes'] += file_stats.get('total_word_boxes', 0)\n",
    "        processing_stats['pdfplumber_pages'] += file_stats.get('pdfplumber_pages', 0)\n",
    "        processing_stats['ocr_pages'] += file_stats.get('ocr_pages', 0)\n",
    "        processing_stats['poor_quality_pages'] += file_stats.get('poor_quality_pages', 0)\n",
    "    \n",
    "    # Print final statistics\n",
    "    print_processing_summary(processing_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7c4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_boxes_with_layout(page, page_num, method='pdfplumber'):\n",
    "    \"\"\"Extract word boxes with comprehensive layout analysis including document positioning\"\"\"\n",
    "    \n",
    "    word_boxes = []\n",
    "    text_blocks = []\n",
    "    \n",
    "    try:\n",
    "        if method == 'pdfplumber':\n",
    "            # First, let's check what's available in the page\n",
    "            try:\n",
    "                # Try basic word extraction first\n",
    "                words = page.extract_words(\n",
    "                    x_tolerance=3,\n",
    "                    y_tolerance=3,\n",
    "                    keep_blank_chars=False\n",
    "                )\n",
    "                \n",
    "                # Debug: Check what attributes are available\n",
    "                if words:\n",
    "                    first_word = words[0]\n",
    "                    available_attrs = list(first_word.keys())\n",
    "                    print(f\"      🔍 Page {page_num} - Available word attributes: {available_attrs}\")\n",
    "                    \n",
    "                    # Check for required attributes\n",
    "                    required_attrs = ['text', 'x0', 'y0', 'x1', 'y1']\n",
    "                    missing_attrs = [attr for attr in required_attrs if attr not in available_attrs]\n",
    "                    \n",
    "                    if missing_attrs:\n",
    "                        print(f\"      ⚠️  Page {page_num} - Missing required attributes: {missing_attrs}\")\n",
    "                        # Try alternative extraction methods\n",
    "                        return extract_word_boxes_alternative(page, page_num)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      ❌ Basic word extraction failed for page {page_num}: {e}\")\n",
    "                return extract_word_boxes_alternative(page, page_num)\n",
    "            \n",
    "            # Process each word with comprehensive error handling\n",
    "            for idx, word in enumerate(words):\n",
    "                try:\n",
    "                    # Validate required attributes exist\n",
    "                    if not all(attr in word for attr in ['text', 'x0', 'y0', 'x1', 'y1']):\n",
    "                        print(f\"      ⚠️  Page {page_num}, Word {idx}: Missing required coordinates\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Create word box with safe attribute access\n",
    "                    word_box = WordBox(\n",
    "                        text=word.get('text', ''),\n",
    "                        x0=float(word.get('x0', 0)),\n",
    "                        y0=float(word.get('y0', 0)),\n",
    "                        x1=float(word.get('x1', 0)),\n",
    "                        y1=float(word.get('y1', 0)),\n",
    "                        width=float(word.get('x1', 0)) - float(word.get('x0', 0)),\n",
    "                        height=float(word.get('y1', 0)) - float(word.get('y0', 0)),\n",
    "                        fontname=word.get('fontname'),\n",
    "                        fontsize=word.get('size'),\n",
    "                        fontcolor=word.get('fontcolor'),\n",
    "                        doctop=word.get('doctop'),\n",
    "                        upright=word.get('upright'),\n",
    "                        top=word.get('top'),\n",
    "                        bottom=word.get('bottom'),\n",
    "                        left=word.get('left'),\n",
    "                        right=word.get('right'),\n",
    "                        page_number=page_num,\n",
    "                        word_index=idx\n",
    "                    )\n",
    "                    word_boxes.append(word_box)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      ⚠️  Page {page_num}, Word {idx}: Failed to create word box: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            # Extract text blocks for layout analysis\n",
    "            try:\n",
    "                text_blocks = page.extract_text_simple()\n",
    "            except:\n",
    "                text_blocks = []\n",
    "            \n",
    "        else:  # OCR method\n",
    "            word_boxes = extract_word_boxes_ocr(page, page_num)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ Word box extraction failed for page {page_num}: {e}\")\n",
    "        return extract_word_boxes_alternative(page, page_num)\n",
    "    \n",
    "    print(f\"      ✅ Page {page_num}: Extracted {len(word_boxes)} word boxes\")\n",
    "    return word_boxes, text_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "074102b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_boxes_alternative(page, page_num):\n",
    "    \"\"\"Alternative word box extraction when standard method fails\"\"\"\n",
    "    \n",
    "    word_boxes = []\n",
    "    text_blocks = []\n",
    "    \n",
    "    try:\n",
    "        # Method 1: Try extracting characters and grouping them\n",
    "        print(f\"      🔄 Page {page_num}: Trying character-based extraction...\")\n",
    "        \n",
    "        try:\n",
    "            chars = page.chars\n",
    "            if chars:\n",
    "                # Group characters into words\n",
    "                words = group_chars_into_words(chars, page_num)\n",
    "                word_boxes.extend(words)\n",
    "                print(f\"      ✅ Page {page_num}: Character-based extraction found {len(words)} words\")\n",
    "            else:\n",
    "                print(f\"      ⚠️  Page {page_num}: No characters found\")\n",
    "        except Exception as e:\n",
    "            print(f\"      ❌ Character-based extraction failed: {e}\")\n",
    "        \n",
    "        # Method 2: If character extraction fails, try text-based estimation\n",
    "        if not word_boxes:\n",
    "            print(f\"      🔄 Page {page_num}: Trying text-based estimation...\")\n",
    "            word_boxes = extract_word_boxes_from_text(page, page_num)\n",
    "        \n",
    "        # Extract text blocks\n",
    "        try:\n",
    "            text_blocks = page.extract_text_simple()\n",
    "        except:\n",
    "            text_blocks = []\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ Alternative word box extraction failed for page {page_num}: {e}\")\n",
    "        return [], []\n",
    "    \n",
    "    return word_boxes, text_blocks\n",
    "\n",
    "def group_chars_into_words(chars, page_num):\n",
    "    \"\"\"Group characters into words with bounding boxes\"\"\"\n",
    "    \n",
    "    if not chars:\n",
    "        return []\n",
    "    \n",
    "    words = []\n",
    "    current_word = []\n",
    "    word_index = 0\n",
    "    \n",
    "    # Sort characters by position (top to bottom, left to right)\n",
    "    sorted_chars = sorted(chars, key=lambda c: (c.get('top', 0), c.get('x0', 0)))\n",
    "    \n",
    "    for char in sorted_chars:\n",
    "        if not char.get('text', '').strip():\n",
    "            continue\n",
    "        \n",
    "        # If this is a space or significant gap, end current word\n",
    "        if (char.get('text', '') == ' ' or \n",
    "            (current_word and \n",
    "             abs(char.get('x0', 0) - current_word[-1].get('x1', 0)) > 5)):\n",
    "            \n",
    "            if current_word:\n",
    "                # Create word box from current word\n",
    "                word_box = create_word_box_from_chars(current_word, page_num, word_index)\n",
    "                if word_box:\n",
    "                    words.append(word_box)\n",
    "                    word_index += 1\n",
    "                current_word = []\n",
    "        \n",
    "        # Add character to current word\n",
    "        if char.get('text', '').strip():\n",
    "            current_word.append(char)\n",
    "    \n",
    "    # Handle last word\n",
    "    if current_word:\n",
    "        word_box = create_word_box_from_chars(current_word, page_num, word_index)\n",
    "        if word_box:\n",
    "            words.append(word_box)\n",
    "    \n",
    "    return words\n",
    "\n",
    "def create_word_box_from_chars(chars, page_num, word_index):\n",
    "    \"\"\"Create a word box from a list of characters\"\"\"\n",
    "    \n",
    "    if not chars:\n",
    "        return None\n",
    "    \n",
    "    # Get bounding box from characters\n",
    "    x0 = min(char.get('x0', 0) for char in chars)\n",
    "    y0 = min(char.get('top', 0) for char in chars)\n",
    "    x1 = max(char.get('x1', 0) for char in chars)\n",
    "    y1 = max(char.get('bottom', 0) for char in chars)\n",
    "    \n",
    "    # Combine text\n",
    "    text = ''.join(char.get('text', '') for char in chars)\n",
    "    \n",
    "    if not text.strip():\n",
    "        return None\n",
    "    \n",
    "    # Get font info from first character\n",
    "    first_char = chars[0]\n",
    "    \n",
    "    return WordBox(\n",
    "        text=text.strip(),\n",
    "        x0=float(x0),\n",
    "        y0=float(y0),\n",
    "        x1=float(x1),\n",
    "        y1=float(y1),\n",
    "        width=float(x1 - x0),\n",
    "        height=float(y1 - y0),\n",
    "        fontname=first_char.get('fontname'),\n",
    "        fontsize=first_char.get('size'),\n",
    "        fontcolor=first_char.get('fontcolor'),\n",
    "        page_number=page_num,\n",
    "        word_index=word_index\n",
    "    )\n",
    "\n",
    "def extract_word_boxes_from_text(page, page_num):\n",
    "    \"\"\"Extract word boxes by estimating positions from text\"\"\"\n",
    "    \n",
    "    word_boxes = []\n",
    "    \n",
    "    try:\n",
    "        # Get page text\n",
    "        text = page.extract_text()\n",
    "        if not text:\n",
    "            return []\n",
    "        \n",
    "        # Get page dimensions\n",
    "        page_width = page.width if hasattr(page, 'width') else 612\n",
    "        page_height = page.height if hasattr(page, 'height') else 792\n",
    "        \n",
    "        # Split into lines and words\n",
    "        lines = text.split('\\n')\n",
    "        word_index = 0\n",
    "        \n",
    "        for line_num, line in enumerate(lines):\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            \n",
    "            words = line.split()\n",
    "            if not words:\n",
    "                continue\n",
    "            \n",
    "            # Estimate line position\n",
    "            line_y = line_num * 15  # Rough estimate: 15 points per line\n",
    "            \n",
    "            # Distribute words across line width\n",
    "            char_width = page_width / 80  # Rough estimate: 80 chars per line\n",
    "            word_width = page_width / len(words) if words else char_width * 5\n",
    "            \n",
    "            for word_num, word in enumerate(words):\n",
    "                if not word.strip():\n",
    "                    continue\n",
    "                \n",
    "                # Estimate word position\n",
    "                word_x = word_num * word_width\n",
    "                word_width_actual = len(word) * char_width\n",
    "                \n",
    "                word_box = WordBox(\n",
    "                    text=word.strip(),\n",
    "                    x0=float(word_x),\n",
    "                    y0=float(line_y),\n",
    "                    x1=float(word_x + word_width_actual),\n",
    "                    y1=float(line_y + 12),  # Rough estimate: 12 points height\n",
    "                    width=float(word_width_actual),\n",
    "                    height=12.0,\n",
    "                    page_number=page_num,\n",
    "                    word_index=word_index\n",
    "                )\n",
    "                word_boxes.append(word_box)\n",
    "                word_index += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ Text-based word box extraction failed: {e}\")\n",
    "    \n",
    "    return word_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d694c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCED VERSION: process_single_pdf with LayoutLMv3 integration\n",
    "def process_single_pdf_enhanced(pdf_path, output_dir, filename, table_settings, generate_layoutlmv3=True):\n",
    "    \"\"\"Process a single PDF file with comprehensive quality assessment and word box extraction\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file to process\n",
    "        output_dir (str): Directory to save output files\n",
    "        filename (str): Name of the PDF file\n",
    "        table_settings (dict): Settings for table extraction\n",
    "        generate_layoutlmv3 (bool, optional): Whether to generate LayoutLMv3-compatible output. Defaults to True.\n",
    "    \"\"\"\n",
    "    # Create output directory for tables\n",
    "    tables_dir = os.path.join(output_dir, \"tables\")\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "    \n",
    "    # (Optional) Extract tables from all pages\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num in range(len(pdf.pages)):\n",
    "            extract_and_integrate_tables(\n",
    "                pdf_path=pdf_path,\n",
    "                output_dir=tables_dir,\n",
    "                page_num=page_num,\n",
    "                settings=table_settings\n",
    "            )\n",
    "    base_name = filename.replace('.pdf', '')\n",
    "    output_file = os.path.join(output_dir, f\"{base_name}_extracted.txt\")\n",
    "    metadata_file = os.path.join(output_dir, f\"{base_name}_metadata.json\")\n",
    "    wordboxes_file = os.path.join(output_dir, f\"{base_name}_wordboxes.json\")\n",
    "    layout_file = os.path.join(output_dir, f\"{base_name}_layout.json\")\n",
    "    layoutlmv3_file = os.path.join(output_dir, f\"{base_name}_layoutlmv3.json\")  # NEW!\n",
    "    \n",
    "    # Skip if already processed (including LayoutLMv3 file if requested)\n",
    "    files_to_check = [output_file, metadata_file, wordboxes_file, layout_file]\n",
    "    if generate_layoutlmv3:\n",
    "        files_to_check.append(layoutlmv3_file)\n",
    "    \n",
    "    if all(os.path.exists(f) for f in files_to_check):\n",
    "        print(f\"  ⏩ Already processed{' (including LayoutLMv3)' if generate_layoutlmv3 else ''}: {base_name}\")\n",
    "        return load_existing_stats(metadata_file)\n",
    "    \n",
    "    file_stats = {\n",
    "        'filename': filename,\n",
    "        'total_pages': 0,\n",
    "        'pdfplumber_pages': 0,\n",
    "        'ocr_pages': 0,\n",
    "        'poor_quality_pages': 0,\n",
    "        'total_word_boxes': 0,\n",
    "        'processing_time': 0,\n",
    "        'page_details': []\n",
    "    }\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            print(f\"  📄 Total pages: {len(pdf.pages)}\")\n",
    "            file_stats['total_pages'] = len(pdf.pages)\n",
    "            \n",
    "            extracted_pages = []\n",
    "            all_word_boxes = []\n",
    "            all_page_layouts = []\n",
    "            \n",
    "            # Process each page with quality assessment and word box extraction\n",
    "            for page_num, page in enumerate(pdf.pages, 1):\n",
    "                page_result = extract_page_with_quality_check(page, page_num)\n",
    "                extracted_pages.append(page_result)\n",
    "                all_word_boxes.extend(page_result['word_boxes'])\n",
    "                all_page_layouts.append(page_result['page_layout'])\n",
    "                file_stats['page_details'].append(page_result['metadata'])\n",
    "                \n",
    "                # Update statistics\n",
    "                if page_result['metadata']['method'] == 'pdfplumber':\n",
    "                    file_stats['pdfplumber_pages'] += 1\n",
    "                else:\n",
    "                    file_stats['ocr_pages'] += 1\n",
    "                \n",
    "                if page_result['metadata']['quality_flag']:\n",
    "                    file_stats['poor_quality_pages'] += 1\n",
    "                \n",
    "                file_stats['total_word_boxes'] += len(page_result['word_boxes'])\n",
    "                \n",
    "                # Progress indicator\n",
    "                if page_num % 20 == 0:\n",
    "                    print(f\"    📖 Processed {page_num} pages...\")\n",
    "            \n",
    "            # Save extracted content, word boxes, and layout data\n",
    "            save_extracted_content(extracted_pages, output_file, metadata_file, file_stats)\n",
    "            save_word_boxes_and_layout(all_word_boxes, all_page_layouts, wordboxes_file, layout_file, file_stats)\n",
    "            \n",
    "            # 🆕 AUTOMATICALLY GENERATE LAYOUTLMV3-COMPATIBLE OUTPUT (if requested)\n",
    "            if generate_layoutlmv3:\n",
    "                try:\n",
    "                    print(f\"  🤖 Generating LayoutLMv3 output...\")\n",
    "                    layoutlmv3_data = end(output_filter=\"layout\", input_data=layout_file, output_file=layoutlmv3_file)\n",
    "                    print(f\"  ✅ Generated LayoutLMv3 output: {os.path.basename(layoutlmv3_file)}\")\n",
    "                    \n",
    "                    # Add LayoutLMv3 stats to file_stats\n",
    "                    total_layoutlmv3_words = sum(len(page['words']) for page in layoutlmv3_data['page_layouts'])\n",
    "                    file_stats['layoutlmv3_words'] = total_layoutlmv3_words\n",
    "                    print(f\"  📊 LayoutLMv3: {total_layoutlmv3_words} words across {len(layoutlmv3_data['page_layouts'])} pages\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"  ⚠️  Failed to generate LayoutLMv3 output: {e}\")\n",
    "                    file_stats['layoutlmv3_error'] = str(e)\n",
    "            else:\n",
    "                print(f\"  ⏭️  Skipping LayoutLMv3 generation (generate_layoutlmv3=False)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error processing {filename}: {e}\")\n",
    "        file_stats['error'] = str(e)\n",
    "    \n",
    "    file_stats['processing_time'] = (datetime.now() - start_time).total_seconds()\n",
    "    return file_stats\n",
    "\n",
    "print(\"✅ Enhanced process_single_pdf_enhanced function defined!\")\n",
    "print(\"🔧 This function includes the optional generate_layoutlmv3 parameter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bfaade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENHANCED VERSION: process_all_pdfs with LayoutLMv3 integration\n",
    "def process_all_pdfs_enhanced(generate_layoutlmv3=True):\n",
    "    \"\"\"Enhanced version of process_all_pdfs that includes optional LayoutLMv3 generation\n",
    "    \n",
    "    Args:\n",
    "        generate_layoutlmv3 (bool, optional): Whether to generate LayoutLMv3-compatible output for all files. Defaults to True.\n",
    "    \"\"\"\n",
    "    # Get all PDF files\n",
    "    pdf_files = glob.glob(os.path.join(raw_pdf_dir, \"*.pdf\"))\n",
    "    print(f\"🔍 Found {len(pdf_files)} PDF files to process{' (with LayoutLMv3 generation)' if generate_layoutlmv3 else ''}\")\n",
    "    \n",
    "    processing_stats = {\n",
    "        'total_files': len(pdf_files),\n",
    "        'processed_files': 0,\n",
    "        'failed_files': 0,\n",
    "        'total_pages': 0,\n",
    "        'total_word_boxes': 0,\n",
    "        'total_layoutlmv3_words': 0,  # NEW!\n",
    "        'pdfplumber_pages': 0,\n",
    "        'ocr_pages': 0,\n",
    "        'poor_quality_pages': 0,\n",
    "        'layoutlmv3_success': 0,  # NEW!\n",
    "        'layoutlmv3_failures': 0  # NEW!\n",
    "    }\n",
    "    \n",
    "    for pdf_path in pdf_files:\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        year = filename.split('_')[2][:4]\n",
    "        \n",
    "        print(f\"\\n📄 Processing: {filename}\")\n",
    "        print(f\"📅 Year: {year}\")\n",
    "        \n",
    "        # Create year-specific output directory\n",
    "        year_output_dir = os.path.join(parsed_output_dir, year)\n",
    "        os.makedirs(year_output_dir, exist_ok=True)\n",
    "        \n",
    "        table_settings = {\n",
    "            \"vertical_strategy\": \"lines\",\n",
    "            \"horizontal_strategy\": \"lines\",\n",
    "            \"snap_x_tolerance\": 10,\n",
    "            \"snap_y_tolerance\": 10,\n",
    "            \"join_tolerance\": 3,\n",
    "            \"edge_min_length\": 3,\n",
    "            \"min_words_vertical\": 3,\n",
    "            \"min_words_horizontal\": 1,\n",
    "            \"intersection_tolerance\": 3,\n",
    "            \"text_tolerance\": 3,\n",
    "            \"text_x_tolerance\": 3,\n",
    "            \"text_y_tolerance\": 3\n",
    "        }\n",
    "        \n",
    "        # Process the PDF with optional LayoutLMv3 generation\n",
    "        file_stats = process_single_pdf_enhanced(\n",
    "            pdf_path, \n",
    "            year_output_dir, \n",
    "            filename, \n",
    "            table_settings, \n",
    "            generate_layoutlmv3=generate_layoutlmv3  # Pass the parameter\n",
    "        )\n",
    "        \n",
    "        # Update overall statistics with safe key access\n",
    "        processing_stats['processed_files'] += 1\n",
    "        processing_stats['total_pages'] += file_stats.get('total_pages', 0)\n",
    "        processing_stats['total_word_boxes'] += file_stats.get('total_word_boxes', 0)\n",
    "        processing_stats['pdfplumber_pages'] += file_stats.get('pdfplumber_pages', 0)\n",
    "        processing_stats['ocr_pages'] += file_stats.get('ocr_pages', 0)\n",
    "        processing_stats['poor_quality_pages'] += file_stats.get('poor_quality_pages', 0)\n",
    "        \n",
    "        # NEW: LayoutLMv3 statistics (only if requested)\n",
    "        if generate_layoutlmv3:\n",
    "            if 'layoutlmv3_words' in file_stats:\n",
    "                processing_stats['total_layoutlmv3_words'] += file_stats['layoutlmv3_words']\n",
    "                processing_stats['layoutlmv3_success'] += 1\n",
    "            else:\n",
    "                processing_stats['layoutlmv3_failures'] += 1\n",
    "    \n",
    "    # Print enhanced final statistics\n",
    "    print_processing_summary_enhanced(processing_stats, generate_layoutlmv3)\n",
    "\n",
    "def print_processing_summary_enhanced(processing_stats, include_layoutlmv3=True):\n",
    "    \"\"\"Enhanced processing summary that optionally includes LayoutLMv3 statistics\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"📊 PDF PROCESSING SUMMARY{' (WITH LAYOUTLMV3)' if include_layoutlmv3 else ''}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # File statistics\n",
    "    print(f\"📁 Files Processed:\")\n",
    "    print(f\"  Total files: {processing_stats['total_files']}\")\n",
    "    print(f\"  Successfully processed: {processing_stats['processed_files']}\")\n",
    "    print(f\"  Failed: {processing_stats['failed_files']}\")\n",
    "    print(f\"  Success rate: {(processing_stats['processed_files']/processing_stats['total_files'])*100:.1f}%\")\n",
    "    \n",
    "    # Page statistics\n",
    "    print(f\"\\n📄 Page Statistics:\")\n",
    "    print(f\"  Total pages processed: {processing_stats['total_pages']}\")\n",
    "    print(f\"  PDFplumber extractions: {processing_stats['pdfplumber_pages']}\")\n",
    "    print(f\"  OCR extractions: {processing_stats['ocr_pages']}\")\n",
    "    print(f\"  Poor quality pages: {processing_stats['poor_quality_pages']}\")\n",
    "    \n",
    "    # Word box statistics\n",
    "    print(f\"\\n📦 Word Box Statistics:\")\n",
    "    print(f\"  Total word boxes extracted: {processing_stats['total_word_boxes']}\")\n",
    "    print(f\"  Average word boxes per page: {processing_stats['total_word_boxes']/processing_stats['total_pages']:.1f}\")\n",
    "    \n",
    "    # LayoutLMv3 statistics (only if included)\n",
    "    if include_layoutlmv3:\n",
    "        print(f\"\\n🤖 LayoutLMv3 Statistics:\")\n",
    "        print(f\"  Files with LayoutLMv3 output: {processing_stats['layoutlmv3_success']}\")\n",
    "        print(f\"  LayoutLMv3 generation failures: {processing_stats['layoutlmv3_failures']}\")\n",
    "        print(f\"  Total LayoutLMv3 words: {processing_stats['total_layoutlmv3_words']}\")\n",
    "        if processing_stats['processed_files'] > 0:\n",
    "            print(f\"  LayoutLMv3 success rate: {(processing_stats['layoutlmv3_success']/processing_stats['processed_files'])*100:.1f}%\")\n",
    "        if processing_stats['layoutlmv3_success'] > 0:\n",
    "            print(f\"  Average LayoutLMv3 words per file: {processing_stats['total_layoutlmv3_words']/processing_stats['layoutlmv3_success']:.1f}\")\n",
    "    \n",
    "    # Quality metrics\n",
    "    if processing_stats['total_pages'] > 0:\n",
    "        pdfplumber_rate = (processing_stats['pdfplumber_pages'] / processing_stats['total_pages']) * 100\n",
    "        ocr_rate = (processing_stats['ocr_pages'] / processing_stats['total_pages']) * 100\n",
    "        poor_quality_rate = (processing_stats['poor_quality_pages'] / processing_stats['total_pages']) * 100\n",
    "        \n",
    "        print(f\"\\n⭐ Quality Metrics:\")\n",
    "        print(f\"  PDFplumber success rate: {pdfplumber_rate:.1f}%\")\n",
    "        print(f\"  OCR fallback rate: {ocr_rate:.1f}%\")\n",
    "        print(f\"  Poor quality rate: {poor_quality_rate:.1f}%\")\n",
    "    \n",
    "    # Performance metrics\n",
    "    print(f\"\\n⚡ Performance:\")\n",
    "    print(f\"  Average pages per file: {processing_stats['total_pages']/processing_stats['processed_files']:.1f}\")\n",
    "    print(f\"  Average word boxes per file: {processing_stats['total_word_boxes']/processing_stats['processed_files']:.1f}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"🎉 Processing completed successfully!\")\n",
    "    print(f\"📦 Word boxes and layout data saved\")\n",
    "    if include_layoutlmv3:\n",
    "        print(f\"🤖 LayoutLMv3 files ready for model input\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "print(\"✅ Enhanced processing functions defined!\")\n",
    "print(\"📝 Usage examples:\")\n",
    "print(\"  - process_all_pdfs_enhanced()  # With LayoutLMv3 (default)\")\n",
    "print(\"  - process_all_pdfs_enhanced(generate_layoutlmv3=False)  # Skip LayoutLMv3\")\n",
    "print(\"  - process_single_pdf_enhanced(pdf_path, output_dir, filename, settings)  # Single file with LayoutLMv3\")\n",
    "print(\"  - process_single_pdf_enhanced(pdf_path, output_dir, filename, settings, generate_layoutlmv3=False)  # Single file without LayoutLMv3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a38450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab0a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_page_layout(word_boxes, page_width, page_height):\n",
    "    \"\"\"Analyze page layout and determine reading order with comprehensive metrics\"\"\"\n",
    "    \n",
    "    if not word_boxes:\n",
    "        return {\n",
    "            'columns': 0,\n",
    "            'rows': 0,\n",
    "            'text_density': 0,\n",
    "            'layout_type': 'empty',\n",
    "            'reading_order': [],\n",
    "            'avg_font_size': 0,\n",
    "            'font_size_variance': 0,\n",
    "            'aspect_ratio': 0,\n",
    "            'text_flow_analysis': {}\n",
    "        }\n",
    "    \n",
    "    # Calculate text density\n",
    "    total_text_area = sum(box.area for box in word_boxes)\n",
    "    page_area = page_width * page_height\n",
    "    text_density = total_text_area / page_area if page_area > 0 else 0\n",
    "    \n",
    "    # Determine layout type based on word distribution\n",
    "    x_positions = [box.center_x for box in word_boxes]\n",
    "    y_positions = [box.center_y for box in word_boxes]\n",
    "    \n",
    "    # Simple column detection\n",
    "    x_sorted = sorted(set(x_positions))\n",
    "    column_gaps = [x_sorted[i+1] - x_sorted[i] for i in range(len(x_sorted)-1)]\n",
    "    avg_gap = sum(column_gaps) / len(column_gaps) if column_gaps else 0\n",
    "    \n",
    "    # Estimate number of columns\n",
    "    estimated_columns = max(1, int(page_width / (avg_gap + 50)) if avg_gap > 0 else 1)\n",
    "    \n",
    "    # Determine reading order\n",
    "    reading_order = determine_reading_order(word_boxes, estimated_columns)\n",
    "    \n",
    "    # Classify layout type\n",
    "    layout_type = classify_layout_type(word_boxes, estimated_columns, text_density)\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    font_sizes = [box.fontsize for box in word_boxes if box.fontsize is not None]\n",
    "    avg_font_size = np.mean(font_sizes) if font_sizes else 0\n",
    "    font_size_variance = np.var(font_sizes) if len(font_sizes) > 1 else 0\n",
    "    \n",
    "    x_spread = max(x_positions) - min(x_positions) if x_positions else 0\n",
    "    y_spread = max(y_positions) - min(y_positions) if y_positions else 0\n",
    "    aspect_ratio = x_spread / y_spread if y_spread > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'columns': estimated_columns,\n",
    "        'rows': len(set(y_positions)),\n",
    "        'text_density': text_density,\n",
    "        'layout_type': layout_type,\n",
    "        'reading_order': reading_order,\n",
    "        'avg_font_size': avg_font_size,\n",
    "        'font_size_variance': font_size_variance,\n",
    "        'aspect_ratio': aspect_ratio,\n",
    "        'text_flow_analysis': {\n",
    "            'x_spread': x_spread,\n",
    "            'y_spread': y_spread,\n",
    "            'word_count': len(word_boxes),\n",
    "            'unique_x_positions': len(set(x_positions)),\n",
    "            'unique_y_positions': len(set(y_positions))\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3c13be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document_positioning(word_boxes):\n",
    "    \"\"\"Analyze document-level positioning and text orientation\"\"\"\n",
    "    \n",
    "    if not word_boxes:\n",
    "        return {\n",
    "            'total_document_height': 0,\n",
    "            'rotated_text_count': 0,\n",
    "            'normal_text_count': 0,\n",
    "            'position_analysis': {}\n",
    "        }\n",
    "    \n",
    "    # Analyze document positioning\n",
    "    doctop_values = [box.doctop for box in word_boxes if box.doctop is not None]\n",
    "    upright_values = [box.upright for box in word_boxes if box.upright is not None]\n",
    "    \n",
    "    analysis = {\n",
    "        'total_document_height': max(doctop_values) if doctop_values else 0,\n",
    "        'rotated_text_count': sum(1 for upright in upright_values if upright is False),\n",
    "        'normal_text_count': sum(1 for upright in upright_values if upright is True),\n",
    "        'position_analysis': {\n",
    "            'min_doctop': min(doctop_values) if doctop_values else 0,\n",
    "            'max_doctop': max(doctop_values) if doctop_values else 0,\n",
    "            'avg_doctop': np.mean(doctop_values) if doctop_values else 0,\n",
    "            'rotation_rate': sum(1 for upright in upright_values if upright is False) / len(upright_values) if upright_values else 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee727620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotated_text_boxes(word_boxes):\n",
    "    \"\"\"Extract and analyze rotated text boxes\"\"\"\n",
    "    \n",
    "    rotated_boxes = [box for box in word_boxes if box.upright is False]\n",
    "    \n",
    "    if not rotated_boxes:\n",
    "        return {\n",
    "            'rotated_boxes': [],\n",
    "            'rotation_analysis': {\n",
    "                'count': 0,\n",
    "                'percentage': 0,\n",
    "                'common_rotations': []\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Analyze rotation patterns\n",
    "    rotation_analysis = {\n",
    "        'count': len(rotated_boxes),\n",
    "        'percentage': (len(rotated_boxes) / len(word_boxes)) * 100,\n",
    "        'common_rotations': []  # Could be extended to detect rotation angles\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'rotated_boxes': rotated_boxes,\n",
    "        'rotation_analysis': rotation_analysis\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83f8bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_word_boxes_ocr(page, page_num):\n",
    "    \"\"\"Extract word boxes using OCR with bounding box information\"\"\"\n",
    "    \n",
    "    word_boxes = []\n",
    "    \n",
    "    try:\n",
    "        # Convert page to image with high resolution for better OCR\n",
    "        page_image = page.to_image(resolution=300)\n",
    "        pil_image = page_image.original\n",
    "        \n",
    "        # Get detailed OCR data with bounding boxes\n",
    "        ocr_data = pytesseract.image_to_data(\n",
    "            pil_image, \n",
    "            lang='eng',\n",
    "            output_type=pytesseract.Output.DICT\n",
    "        )\n",
    "        \n",
    "        # Process OCR results\n",
    "        for idx, (text, conf, x, y, w, h) in enumerate(zip(\n",
    "            ocr_data['text'], \n",
    "            ocr_data['conf'], \n",
    "            ocr_data['left'], \n",
    "            ocr_data['top'], \n",
    "            ocr_data['width'], \n",
    "            ocr_data['height']\n",
    "        )):\n",
    "            # Filter low confidence and empty text\n",
    "            if int(conf) > 30 and text.strip():\n",
    "                word_box = WordBox(\n",
    "                    text=text.strip(),\n",
    "                    x0=float(x),\n",
    "                    y0=float(y),\n",
    "                    x1=float(x + w),\n",
    "                    y1=float(y + h),\n",
    "                    width=float(w),\n",
    "                    height=float(h),\n",
    "                    confidence=float(conf),\n",
    "                    page_number=page_num,\n",
    "                    word_index=idx\n",
    "                )\n",
    "                word_boxes.append(word_box)\n",
    "        \n",
    "        print(f\"      📝 OCR extracted {len(word_boxes)} word boxes from page {page_num}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ OCR word box extraction failed for page {page_num}: {e}\")\n",
    "    \n",
    "    return word_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de09ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_reading_order(word_boxes, estimated_columns):\n",
    "    \"\"\"Determine reading order of words (top-to-bottom, left-to-right)\"\"\"\n",
    "    \n",
    "    if not word_boxes:\n",
    "        return []\n",
    "    \n",
    "    # Method 1: Simple top-to-bottom, left-to-right sorting\n",
    "    def simple_reading_order():\n",
    "        # Sort by Y position first (top to bottom), then by X position (left to right)\n",
    "        sorted_boxes = sorted(word_boxes, key=lambda box: (box.y0, box.x0))\n",
    "        return [box.word_index for box in sorted_boxes]\n",
    "    \n",
    "    # Method 2: Column-aware reading order\n",
    "    def column_aware_reading_order():\n",
    "        if estimated_columns <= 1:\n",
    "            return simple_reading_order()\n",
    "        \n",
    "        # Group words by estimated columns\n",
    "        page_width = max(box.x1 for box in word_boxes) if word_boxes else 0\n",
    "        column_width = page_width / estimated_columns\n",
    "        \n",
    "        # Assign words to columns\n",
    "        column_groups = [[] for _ in range(estimated_columns)]\n",
    "        \n",
    "        for box in word_boxes:\n",
    "            column_idx = min(int(box.center_x / column_width), estimated_columns - 1)\n",
    "            column_groups[column_idx].append(box)\n",
    "        \n",
    "        # Sort each column and combine\n",
    "        reading_order = []\n",
    "        for column in column_groups:\n",
    "            column_sorted = sorted(column, key=lambda box: box.y0)\n",
    "            reading_order.extend([box.word_index for box in column_sorted])\n",
    "        \n",
    "        return reading_order\n",
    "    \n",
    "    # Method 3: Advanced reading order with line detection\n",
    "    def advanced_reading_order():\n",
    "        if len(word_boxes) < 10:  # Too few words for advanced analysis\n",
    "            return simple_reading_order()\n",
    "        \n",
    "        # Group words into lines based on Y-coordinate clustering\n",
    "        y_positions = [box.y0 for box in word_boxes]\n",
    "        y_sorted = sorted(set(y_positions))\n",
    "        \n",
    "        # Detect line breaks (significant Y gaps)\n",
    "        line_breaks = []\n",
    "        for i in range(len(y_sorted) - 1):\n",
    "            if y_sorted[i+1] - y_sorted[i] > 15:  # Threshold for line break\n",
    "                line_breaks.append((y_sorted[i] + y_sorted[i+1]) / 2)\n",
    "        \n",
    "        # Group words into lines\n",
    "        lines = []\n",
    "        current_line = []\n",
    "        \n",
    "        for box in sorted(word_boxes, key=lambda b: b.y0):\n",
    "            if not current_line or not any(abs(box.y0 - line_box.y0) < 10 for line_box in current_line):\n",
    "                if current_line:\n",
    "                    lines.append(current_line)\n",
    "                current_line = [box]\n",
    "            else:\n",
    "                current_line.append(box)\n",
    "        \n",
    "        if current_line:\n",
    "            lines.append(current_line)\n",
    "        \n",
    "        # Sort each line left-to-right, then combine lines\n",
    "        reading_order = []\n",
    "        for line in lines:\n",
    "            line_sorted = sorted(line, key=lambda box: box.x0)\n",
    "            reading_order.extend([box.word_index for box in line_sorted])\n",
    "        \n",
    "        return reading_order\n",
    "    \n",
    "    # Choose method based on complexity\n",
    "    if estimated_columns > 2 and len(word_boxes) > 50:\n",
    "        return advanced_reading_order()\n",
    "    elif estimated_columns > 1:\n",
    "        return column_aware_reading_order()\n",
    "    else:\n",
    "        return simple_reading_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afaffa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_layout_type(word_boxes, estimated_columns, text_density):\n",
    "    \"\"\"Classify the layout type based on word distribution and density\"\"\"\n",
    "    \n",
    "    if not word_boxes:\n",
    "        return 'empty'\n",
    "    \n",
    "    # Analyze word distribution\n",
    "    x_positions = [box.center_x for box in word_boxes]\n",
    "    y_positions = [box.center_y for box in word_boxes]\n",
    "    \n",
    "    # Calculate spreads and statistics\n",
    "    x_spread = max(x_positions) - min(x_positions) if x_positions else 0\n",
    "    y_spread = max(y_positions) - min(y_positions) if y_positions else 0\n",
    "    aspect_ratio = x_spread / y_spread if y_spread > 0 else 0\n",
    "    \n",
    "    # Analyze font size distribution\n",
    "    font_sizes = [box.fontsize for box in word_boxes if box.fontsize is not None]\n",
    "    avg_font_size = np.mean(font_sizes) if font_sizes else 12\n",
    "    font_size_variance = np.var(font_sizes) if len(font_sizes) > 1 else 0\n",
    "    \n",
    "    # Analyze text density patterns\n",
    "    density_thresholds = {\n",
    "        'very_sparse': 0.05,\n",
    "        'sparse': 0.15,\n",
    "        'normal': 0.35,\n",
    "        'dense': 0.55,\n",
    "        'very_dense': 0.75\n",
    "    }\n",
    "    \n",
    "    # Classify based on multiple criteria\n",
    "    if text_density < density_thresholds['very_sparse']:\n",
    "        return 'very_sparse'\n",
    "    elif text_density < density_thresholds['sparse']:\n",
    "        return 'sparse'\n",
    "    elif estimated_columns == 1:\n",
    "        if aspect_ratio < 0.3:\n",
    "            return 'narrow_single_column'\n",
    "        elif font_size_variance > 50:  # High variance in font sizes\n",
    "            return 'mixed_formatting_single_column'\n",
    "        else:\n",
    "            return 'single_column'\n",
    "    elif estimated_columns == 2:\n",
    "        if font_size_variance > 50:\n",
    "            return 'mixed_formatting_two_column'\n",
    "        else:\n",
    "            return 'two_column'\n",
    "    elif estimated_columns >= 3:\n",
    "        if text_density > density_thresholds['dense']:\n",
    "            return 'dense_multi_column'\n",
    "        else:\n",
    "            return 'multi_column'\n",
    "    elif x_spread < y_spread * 0.4:\n",
    "        return 'narrow_column'\n",
    "    elif font_size_variance > 100:  # Very high variance\n",
    "        return 'complex_mixed_layout'\n",
    "    elif text_density > density_thresholds['very_dense']:\n",
    "        return 'very_dense_layout'\n",
    "    else:\n",
    "        return 'mixed_layout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff1942e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_integrate_tables(pdf_path, output_dir, page_num=0, settings=None):\n",
    "    if settings is None:\n",
    "        settings = {\n",
    "            \"vertical_strategy\": \"lines\",\n",
    "            \"horizontal_strategy\": \"lines\",\n",
    "            \"snap_x_tolerance\": 10,\n",
    "            \"snap_y_tolerance\": 10,\n",
    "            \"join_tolerance\": 3,\n",
    "            \"edge_min_length\": 3,\n",
    "            \"min_words_vertical\": 3,\n",
    "            \"min_words_horizontal\": 1,\n",
    "            \"intersection_tolerance\": 3,\n",
    "            \"text_tolerance\": 3,\n",
    "            \"text_x_tolerance\": 3,\n",
    "            \"text_y_tolerance\": 3\n",
    "        }\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[page_num]\n",
    "        tables = page.extract_tables(settings)\n",
    "        \n",
    "        # Group tables by their header (first row)\n",
    "        table_groups = {}\n",
    "        for table in tables:\n",
    "            if not table or not table[0]:\n",
    "                continue\n",
    "            header = tuple(table[0])\n",
    "            rows = table[1:]\n",
    "            if header not in table_groups:\n",
    "                table_groups[header] = []\n",
    "            table_groups[header].extend(rows)\n",
    "        \n",
    "        # Export each group as a single CSV\n",
    "        for idx, (header, rows) in enumerate(table_groups.items()):\n",
    "            df = pd.DataFrame(rows)\n",
    "            csv_path = os.path.join(output_dir, f\"integrated_table_{idx+1}.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            print(f\"Exported integrated table {idx+1} to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ae9806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_pdf(pdf_path, output_dir, filename, table_settings):\n",
    "    \"\"\"Process a single PDF file with comprehensive quality assessment and word box extraction\"\"\"\n",
    "     # Create output directory for tables\n",
    "    tables_dir = os.path.join(output_dir, \"tables\")\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "    \n",
    "    # (Optional) Extract tables from all pages\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num in range(len(pdf.pages)):\n",
    "            extract_and_integrate_tables(\n",
    "                pdf_path=pdf_path,\n",
    "                output_dir=tables_dir,\n",
    "                page_num=page_num,\n",
    "                settings=table_settings\n",
    "            )\n",
    "    base_name = filename.replace('.pdf', '')\n",
    "    output_file = os.path.join(output_dir, f\"{base_name}_extracted.txt\")\n",
    "    metadata_file = os.path.join(output_dir, f\"{base_name}_metadata.json\")\n",
    "    wordboxes_file = os.path.join(output_dir, f\"{base_name}_wordboxes.json\")\n",
    "    layout_file = os.path.join(output_dir, f\"{base_name}_layout.json\")\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if (os.path.exists(output_file) and os.path.exists(metadata_file) and \n",
    "        os.path.exists(wordboxes_file) and os.path.exists(layout_file)):\n",
    "        print(f\"  ⏩ Already processed: {base_name}\")\n",
    "        return load_existing_stats(metadata_file)\n",
    "    \n",
    "    file_stats = {\n",
    "        'filename': filename,\n",
    "        'total_pages': 0,\n",
    "        'pdfplumber_pages': 0,\n",
    "        'ocr_pages': 0,\n",
    "        'poor_quality_pages': 0,\n",
    "        'total_word_boxes': 0,\n",
    "        'processing_time': 0,\n",
    "        'page_details': []\n",
    "    }\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            print(f\"  📄 Total pages: {len(pdf.pages)}\")\n",
    "            file_stats['total_pages'] = len(pdf.pages)\n",
    "            \n",
    "            extracted_pages = []\n",
    "            all_word_boxes = []\n",
    "            all_page_layouts = []\n",
    "            \n",
    "            # Process each page with quality assessment and word box extraction\n",
    "            for page_num, page in enumerate(pdf.pages, 1):\n",
    "                page_result = extract_page_with_quality_check(page, page_num)\n",
    "                extracted_pages.append(page_result)\n",
    "                all_word_boxes.extend(page_result['word_boxes'])\n",
    "                all_page_layouts.append(page_result['page_layout'])\n",
    "                file_stats['page_details'].append(page_result['metadata'])\n",
    "                \n",
    "                # Update statistics\n",
    "                if page_result['metadata']['method'] == 'pdfplumber':\n",
    "                    file_stats['pdfplumber_pages'] += 1\n",
    "                else:\n",
    "                    file_stats['ocr_pages'] += 1\n",
    "                \n",
    "                if page_result['metadata']['quality_flag']:\n",
    "                    file_stats['poor_quality_pages'] += 1\n",
    "                \n",
    "                file_stats['total_word_boxes'] += len(page_result['word_boxes'])\n",
    "                \n",
    "                # Progress indicator\n",
    "                if page_num % 20 == 0:\n",
    "                    print(f\"    📖 Processed {page_num} pages...\")\n",
    "            \n",
    "            # Save extracted content, word boxes, and layout data\n",
    "            save_extracted_content(extracted_pages, output_file, metadata_file, file_stats)\n",
    "            save_word_boxes_and_layout(all_word_boxes, all_page_layouts, wordboxes_file, layout_file, file_stats)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error processing {filename}: {e}\")\n",
    "        file_stats['error'] = str(e)\n",
    "    \n",
    "    file_stats['processing_time'] = (datetime.now() - start_time).total_seconds()\n",
    "    return file_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb7068ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_with_quality_check(page, page_num):\n",
    "    \"\"\"Extract text and word boxes from a single page with comprehensive quality assessment\"\"\"\n",
    "    \n",
    "    # Try pdfplumber first\n",
    "    text = page.extract_text()\n",
    "    \n",
    "    # Quality assessment metrics\n",
    "    char_count = len(text) if text else 0\n",
    "    word_count = len(text.split()) if text else 0\n",
    "    line_count = len(text.split('\\n')) if text else 0\n",
    "    \n",
    "    # Quality thresholds (adjust based on your needs)\n",
    "    min_chars_per_page = 100\n",
    "    max_chars_per_page = 10000\n",
    "    min_words_per_page = 20\n",
    "    \n",
    "    quality_metrics = {\n",
    "        'char_count': char_count,\n",
    "        'word_count': word_count,\n",
    "        'line_count': line_count,\n",
    "        'char_density': char_count / (page.width * page.height) if hasattr(page, 'width') else 0,\n",
    "        'quality_score': 0\n",
    "    }\n",
    "    \n",
    "    # Determine quality and extraction method\n",
    "    if not text or char_count < min_chars_per_page:\n",
    "        # Poor extraction, try OCR\n",
    "        print(f\"    ⚠️  Page {page_num}: Poor pdfplumber extraction ({char_count} chars), trying OCR...\")\n",
    "        text = extract_with_ocr(page)\n",
    "        method = 'tesseract'\n",
    "        quality_flag = True\n",
    "        \n",
    "        # Recalculate metrics for OCR text\n",
    "        quality_metrics.update({\n",
    "            'char_count': len(text) if text else 0,\n",
    "            'word_count': len(text.split()) if text else 0,\n",
    "            'line_count': len(text.split('\\n')) if text else 0\n",
    "        })\n",
    "        \n",
    "    elif char_count > max_chars_per_page:\n",
    "        # Suspiciously long text (might be garbled)\n",
    "        print(f\"    ⚠️  Page {page_num}: Suspiciously long text ({char_count} chars)\")\n",
    "        method = 'pdfplumber'\n",
    "        quality_flag = True\n",
    "        \n",
    "    else:\n",
    "        # Good extraction\n",
    "        method = 'pdfplumber'\n",
    "        quality_flag = False\n",
    "    \n",
    "    # Calculate quality score (0-100)\n",
    "    quality_score = calculate_quality_score(quality_metrics, method)\n",
    "    quality_metrics['quality_score'] = quality_score\n",
    "    \n",
    "    # Extract word boxes and perform layout analysis\n",
    "    word_boxes, text_blocks = extract_word_boxes_with_layout(page, page_num, method)\n",
    "    \n",
    "    # Analyze page layout\n",
    "    layout_analysis = analyze_page_layout(word_boxes, page.width, page.height)\n",
    "    \n",
    "    # Create PageLayout object\n",
    "    page_layout = PageLayout(\n",
    "        page_number=page_num,\n",
    "        page_width=page.width,\n",
    "        page_height=page.height,\n",
    "        word_boxes=word_boxes,\n",
    "        text_blocks=text_blocks,\n",
    "        reading_order=layout_analysis['reading_order'],\n",
    "        layout_analysis=layout_analysis\n",
    "    )\n",
    "    \n",
    "    # Create metadata\n",
    "    metadata = {\n",
    "        'page_number': page_num,\n",
    "        'method': method,\n",
    "        'quality_flag': quality_flag,\n",
    "        'quality_score': quality_score,\n",
    "        'extraction_timestamp': datetime.now().isoformat(),\n",
    "        'word_count': len(word_boxes),\n",
    "        'layout_type': layout_analysis['layout_type'],\n",
    "        'estimated_columns': layout_analysis['columns'],\n",
    "        'text_density': layout_analysis['text_density'],\n",
    "        **quality_metrics\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'text': text or \"\",\n",
    "        'word_boxes': word_boxes,\n",
    "        'page_layout': page_layout,\n",
    "        'metadata': metadata\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a863f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word_boxes_and_layout(all_word_boxes, all_page_layouts, wordboxes_file, layout_file, file_stats):\n",
    "    \"\"\"Save word boxes and layout data as JSON files\"\"\"\n",
    "    \n",
    "    # Save word boxes data\n",
    "    word_boxes_data = {\n",
    "        'file_info': {\n",
    "            'filename': file_stats['filename'],\n",
    "            'processing_date': datetime.now().isoformat(),\n",
    "            'total_word_boxes': len(all_word_boxes),\n",
    "            'total_pages': file_stats['total_pages']\n",
    "        },\n",
    "        'word_boxes': [box.to_dict() for box in all_word_boxes],\n",
    "        'statistics': {\n",
    "            'total_word_boxes': len(all_word_boxes),\n",
    "            'avg_word_boxes_per_page': len(all_word_boxes) / file_stats['total_pages'] if file_stats['total_pages'] > 0 else 0,\n",
    "            'pages_with_word_boxes': len([layout for layout in all_page_layouts if layout.word_boxes])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(wordboxes_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(word_boxes_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # Save layout data\n",
    "    layout_data = {\n",
    "        'file_info': {\n",
    "            'filename': file_stats['filename'],\n",
    "            'processing_date': datetime.now().isoformat(),\n",
    "            'total_pages': file_stats['total_pages']\n",
    "        },\n",
    "        'page_layouts': [layout.to_dict() for layout in all_page_layouts],\n",
    "        'document_analysis': analyze_document_layout(all_page_layouts)\n",
    "    }\n",
    "    \n",
    "    with open(layout_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(layout_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"  📦 Saved word boxes: {os.path.basename(wordboxes_file)}\")\n",
    "    print(f\"  📐 Saved layout data: {os.path.basename(layout_file)}\")\n",
    "    print(f\"  📊 Total word boxes: {len(all_word_boxes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7fa94e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document_layout(page_layouts):\n",
    "    \"\"\"Analyze overall document layout across all pages\"\"\"\n",
    "    \n",
    "    if not page_layouts:\n",
    "        return {'document_type': 'empty', 'analysis': {}}\n",
    "    \n",
    "    # Collect statistics across all pages\n",
    "    layout_types = [layout.layout_type for layout in page_layouts]\n",
    "    column_counts = [layout.estimated_columns for layout in page_layouts]\n",
    "    text_densities = [layout.text_density for layout in page_layouts]\n",
    "    font_sizes = [layout.average_font_size for layout in page_layouts if layout.average_font_size > 0]\n",
    "    \n",
    "    # Analyze document characteristics\n",
    "    most_common_layout = max(set(layout_types), key=layout_types.count) if layout_types else 'unknown'\n",
    "    avg_columns = np.mean(column_counts) if column_counts else 1\n",
    "    avg_text_density = np.mean(text_densities) if text_densities else 0\n",
    "    avg_font_size = np.mean(font_sizes) if font_sizes else 0\n",
    "    \n",
    "    # Determine document type\n",
    "    if most_common_layout in ['single_column', 'narrow_single_column']:\n",
    "        document_type = 'single_column_document'\n",
    "    elif most_common_layout in ['two_column', 'mixed_formatting_two_column']:\n",
    "        document_type = 'two_column_document'\n",
    "    elif most_common_layout in ['multi_column', 'dense_multi_column']:\n",
    "        document_type = 'multi_column_document'\n",
    "    else:\n",
    "        document_type = 'mixed_layout_document'\n",
    "    \n",
    "    return {\n",
    "        'document_type': document_type,\n",
    "        'most_common_layout': most_common_layout,\n",
    "        'average_columns': avg_columns,\n",
    "        'average_text_density': avg_text_density,\n",
    "        'average_font_size': avg_font_size,\n",
    "        'layout_distribution': {layout: layout_types.count(layout) for layout in set(layout_types)},\n",
    "        'column_distribution': {cols: column_counts.count(cols) for cols in set(column_counts)},\n",
    "        'total_pages': len(page_layouts),\n",
    "        'pages_with_content': len([layout for layout in page_layouts if layout.word_boxes])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "232143c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_ocr(page):\n",
    "    \"\"\"Extract text using Tesseract OCR as fallback\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Convert page to image\n",
    "        page_image = page.to_image(resolution=300)  # High resolution for better OCR\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        pil_image = page_image.original\n",
    "        \n",
    "        # Use pytesseract for OCR\n",
    "        text = pytesseract.image_to_string(pil_image, lang='eng')\n",
    "        \n",
    "        return text.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"      ❌ OCR failed: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68a19dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_extracted_content(extracted_pages, output_file, metadata_file, file_stats):\n",
    "    \"\"\"Save extracted text and metadata with page-level granularity\"\"\"\n",
    "    \n",
    "    # Save extracted text with page separators\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"# Extracted Text from {file_stats['filename']}\\n\")\n",
    "        f.write(f\"# Processing Date: {datetime.now().isoformat()}\\n\")\n",
    "        f.write(f\"# Total Pages: {file_stats['total_pages']}\\n\")\n",
    "        f.write(f\"# PDFplumber Pages: {file_stats['pdfplumber_pages']}\\n\")\n",
    "        f.write(f\"# OCR Pages: {file_stats['ocr_pages']}\\n\")\n",
    "        f.write(f\"# Poor Quality Pages: {file_stats['poor_quality_pages']}\\n\\n\")\n",
    "        \n",
    "        for page_data in extracted_pages:\n",
    "            page_num = page_data['metadata']['page_number']\n",
    "            method = page_data['metadata']['method']\n",
    "            quality_score = page_data['metadata']['quality_score']\n",
    "            \n",
    "            f.write(f\"\\n{'='*80}\\n\")\n",
    "            f.write(f\"PAGE {page_num} | Method: {method} | Quality Score: {quality_score}\\n\")\n",
    "            f.write(f\"{'='*80}\\n\\n\")\n",
    "            f.write(page_data['text'])\n",
    "            f.write(f\"\\n\\n\")\n",
    "    \n",
    "    # Save detailed metadata as JSON\n",
    "    metadata = {\n",
    "        'file_info': {\n",
    "            'filename': file_stats['filename'],\n",
    "            'processing_date': datetime.now().isoformat(),\n",
    "            'processing_time_seconds': file_stats['processing_time']\n",
    "        },\n",
    "        'statistics': {\n",
    "            'total_pages': file_stats['total_pages'],\n",
    "            'pdfplumber_pages': file_stats['pdfplumber_pages'],\n",
    "            'ocr_pages': file_stats['ocr_pages'],\n",
    "            'poor_quality_pages': file_stats['poor_quality_pages'],\n",
    "            'success_rate': (file_stats['pdfplumber_pages'] / file_stats['total_pages']) * 100\n",
    "        },\n",
    "        'page_details': file_stats['page_details']\n",
    "    }\n",
    "    \n",
    "    with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"  ✅ Saved: {os.path.basename(output_file)}\")\n",
    "    print(f\"  �� Quality: {file_stats['pdfplumber_pages']}/{file_stats['total_pages']} pages via pdfplumber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6acd3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality_score(metrics, method):\n",
    "    \"\"\"Calculate a quality score (0-100) for the extracted text\"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    # Character count scoring (0-30 points)\n",
    "    char_count = metrics['char_count']\n",
    "    if 200 <= char_count <= 5000:\n",
    "        score += 30\n",
    "    elif 100 <= char_count < 200 or 5000 < char_count <= 8000:\n",
    "        score += 20\n",
    "    elif 50 <= char_count < 100 or 8000 < char_count <= 10000:\n",
    "        score += 10\n",
    "    \n",
    "    # Word count scoring (0-25 points)\n",
    "    word_count = metrics['word_count']\n",
    "    if 50 <= word_count <= 1000:\n",
    "        score += 25\n",
    "    elif 25 <= word_count < 50 or 1000 < word_count <= 1500:\n",
    "        score += 15\n",
    "    elif 10 <= word_count < 25:\n",
    "        score += 10\n",
    "    \n",
    "    # Line count scoring (0-20 points)\n",
    "    line_count = metrics['line_count']\n",
    "    if 10 <= line_count <= 100:\n",
    "        score += 20\n",
    "    elif 5 <= line_count < 10 or 100 < line_count <= 150:\n",
    "        score += 15\n",
    "    elif 2 <= line_count < 5:\n",
    "        score += 10\n",
    "    \n",
    "    # Method bonus (0-25 points)\n",
    "    if method == 'pdfplumber':\n",
    "        score += 25\n",
    "    else:  # tesseract\n",
    "        score += 15\n",
    "    \n",
    "    return min(score, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ce4e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_processing_summary(processing_stats):\n",
    "    \"\"\"Print comprehensive processing summary statistics including word box data\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"📊 PDF PROCESSING SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # File statistics\n",
    "    print(f\"📁 Files Processed:\")\n",
    "    print(f\"  Total files: {processing_stats['total_files']}\")\n",
    "    print(f\"  Successfully processed: {processing_stats['processed_files']}\")\n",
    "    print(f\"  Failed: {processing_stats['failed_files']}\")\n",
    "    print(f\"  Success rate: {(processing_stats['processed_files']/processing_stats['total_files'])*100:.1f}%\")\n",
    "    \n",
    "    # Page statistics\n",
    "    print(f\"\\n📄 Page Statistics:\")\n",
    "    print(f\"  Total pages processed: {processing_stats['total_pages']}\")\n",
    "    print(f\"  PDFplumber extractions: {processing_stats['pdfplumber_pages']}\")\n",
    "    print(f\"  OCR extractions: {processing_stats['ocr_pages']}\")\n",
    "    print(f\"  Poor quality pages: {processing_stats['poor_quality_pages']}\")\n",
    "    \n",
    "    # Word box statistics\n",
    "    print(f\"\\n📦 Word Box Statistics:\")\n",
    "    print(f\"  Total word boxes extracted: {processing_stats['total_word_boxes']}\")\n",
    "    print(f\"  Average word boxes per page: {processing_stats['total_word_boxes']/processing_stats['total_pages']:.1f}\")\n",
    "    \n",
    "    # Quality metrics\n",
    "    if processing_stats['total_pages'] > 0:\n",
    "        pdfplumber_rate = (processing_stats['pdfplumber_pages'] / processing_stats['total_pages']) * 100\n",
    "        ocr_rate = (processing_stats['ocr_pages'] / processing_stats['total_pages']) * 100\n",
    "        poor_quality_rate = (processing_stats['poor_quality_pages'] / processing_stats['total_pages']) * 100\n",
    "        \n",
    "        print(f\"\\n�� Quality Metrics:\")\n",
    "        print(f\"  PDFplumber success rate: {pdfplumber_rate:.1f}%\")\n",
    "        print(f\"  OCR fallback rate: {ocr_rate:.1f}%\")\n",
    "        print(f\"  Poor quality rate: {poor_quality_rate:.1f}%\")\n",
    "    \n",
    "    # Performance metrics\n",
    "    print(f\"\\n⚡ Performance:\")\n",
    "    print(f\"  Average pages per file: {processing_stats['total_pages']/processing_stats['processed_files']:.1f}\")\n",
    "    print(f\"  Average word boxes per file: {processing_stats['total_word_boxes']/processing_stats['processed_files']:.1f}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\n💡 Recommendations:\")\n",
    "    if processing_stats['ocr_pages'] > processing_stats['total_pages'] * 0.3:\n",
    "        print(f\"  ⚠️  High OCR usage ({ocr_rate:.1f}%) - consider improving PDF quality\")\n",
    "    if processing_stats['poor_quality_pages'] > processing_stats['total_pages'] * 0.1:\n",
    "        print(f\"  ⚠️  High poor quality rate ({poor_quality_rate:.1f}%) - review extraction parameters\")\n",
    "    if processing_stats['pdfplumber_pages'] > processing_stats['total_pages'] * 0.8:\n",
    "        print(f\"  ✅ Good extraction quality - most pages processed with PDFplumber\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"🎉 Processing completed successfully!\")\n",
    "    print(f\"📦 Word boxes and layout data saved for LayoutLMv3 analysis\")\n",
    "    print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab9145bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_stats(metadata_file):\n",
    "    \"\"\"Load existing statistics from metadata file with comprehensive backward compatibility\"\"\"\n",
    "    try:\n",
    "        with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "            metadata = json.load(f)\n",
    "            \n",
    "            # Get statistics with fallback values for missing keys\n",
    "            stats = metadata.get('statistics', {})\n",
    "            \n",
    "            # Calculate total_word_boxes from page_details if not present\n",
    "            total_word_boxes = stats.get('total_word_boxes', 0)\n",
    "            if total_word_boxes == 0:\n",
    "                # Try to calculate from page_details if available\n",
    "                page_details = metadata.get('page_details', [])\n",
    "                if page_details:\n",
    "                    total_word_boxes = sum(page.get('word_count', 0) for page in page_details)\n",
    "            \n",
    "            return {\n",
    "                'total_pages': stats.get('total_pages', 0),\n",
    "                'pdfplumber_pages': stats.get('pdfplumber_pages', 0),\n",
    "                'ocr_pages': stats.get('ocr_pages', 0),\n",
    "                'poor_quality_pages': stats.get('poor_quality_pages', 0),\n",
    "                'total_word_boxes': total_word_boxes\n",
    "            }\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ⚠️  Metadata file not found: {metadata_file}\")\n",
    "        return get_default_stats()\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"  ⚠️  Invalid JSON in metadata file: {e}\")\n",
    "        return get_default_stats()\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️  Could not load existing stats: {e}\")\n",
    "        return get_default_stats()\n",
    "\n",
    "def get_default_stats():\n",
    "    \"\"\"Return default statistics structure\"\"\"\n",
    "    return {\n",
    "        'total_pages': 0,\n",
    "        'pdfplumber_pages': 0,\n",
    "        'ocr_pages': 0,\n",
    "        'poor_quality_pages': 0,\n",
    "        'total_word_boxes': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f06598",
   "metadata": {},
   "source": [
    "Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37253ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end(output_filter=None, input_data=None, output_file=None):\n",
    "    \"\"\"\n",
    "    End function that filters and formats the extracted data to match LayoutLMv3 input schema.\n",
    "    \n",
    "    Args:\n",
    "        output_filter (str, optional): Filter type. If \"layout\", output is filtered to match LayoutLMv3 schema.\n",
    "        input_data (dict or str, optional): Input data - can be layout file path or loaded data dict.\n",
    "                                          If None, uses the most recent layout file from parsed MSFT data.\n",
    "        output_file (str, optional): Output file path. If None, saves to default location.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Filtered data in LayoutLMv3 format (if output_filter=\"layout\")\n",
    "        dict: Original data (if output_filter is None or other values)\n",
    "    \"\"\"\n",
    "    \n",
    "    # If no input data provided, find the most recent layout file\n",
    "    if input_data is None:\n",
    "        input_data = find_most_recent_layout_file()\n",
    "    \n",
    "    # Load data if input_data is a file path\n",
    "    if isinstance(input_data, str):\n",
    "        with open(input_data, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    else:\n",
    "        data = input_data\n",
    "    \n",
    "    # Apply filter if specified\n",
    "    if output_filter == \"layout\":\n",
    "        filtered_data = transform_to_layoutlmv3_schema(data)\n",
    "    else:\n",
    "        filtered_data = data\n",
    "    \n",
    "    # Save to output file if specified\n",
    "    if output_file:\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(filtered_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"✅ Saved filtered data to: {output_file}\")\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def find_most_recent_layout_file():\n",
    "    \"\"\"Find the most recent layout file from the parsed MSFT data.\"\"\"\n",
    "    \n",
    "    msft_parsed_dir = \"../data/parsed/MSFT\"\n",
    "    layout_files = []\n",
    "    \n",
    "    # Search for layout files in all year subdirectories\n",
    "    for year_dir in os.listdir(msft_parsed_dir):\n",
    "        year_path = os.path.join(msft_parsed_dir, year_dir)\n",
    "        if os.path.isdir(year_path):\n",
    "            for file in os.listdir(year_path):\n",
    "                if file.endswith(\"_layout.json\"):\n",
    "                    layout_files.append(os.path.join(year_path, file))\n",
    "    \n",
    "    if not layout_files:\n",
    "        raise FileNotFoundError(\"No layout files found in the parsed MSFT data\")\n",
    "    \n",
    "    # Sort by modification time and return the most recent\n",
    "    layout_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "    most_recent = layout_files[0]\n",
    "    \n",
    "    print(f\"📁 Using most recent layout file: {os.path.basename(most_recent)}\")\n",
    "    return most_recent\n",
    "\n",
    "\n",
    "def transform_to_layoutlmv3_schema(layout_data):\n",
    "    \"\"\"\n",
    "    Transform layout data to match LayoutLMv3 input schema.\n",
    "    \n",
    "    Args:\n",
    "        layout_data (dict): Original layout data from the extraction process\n",
    "    \n",
    "    Returns:\n",
    "        dict: Data formatted according to LayoutLMv3 schema\n",
    "    \"\"\"\n",
    "    \n",
    "    file_info = layout_data.get('file_info', {})\n",
    "    page_layouts = layout_data.get('page_layouts', [])\n",
    "    \n",
    "    # Create the schema-compliant structure\n",
    "    layoutlmv3_data = {\n",
    "        \"file_info\": {\n",
    "            \"filename\": file_info.get('filename', 'unknown'),\n",
    "            \"total_pages\": len(page_layouts)\n",
    "        },\n",
    "        \"page_layouts\": []\n",
    "    }\n",
    "    \n",
    "    # Transform each page layout\n",
    "    for page_layout in page_layouts:\n",
    "        # Extract basic page information\n",
    "        page_number = page_layout.get('page_number', 0)\n",
    "        page_width = page_layout.get('page_width', 612.0)\n",
    "        page_height = page_layout.get('page_height', 792.0)\n",
    "        word_boxes = page_layout.get('word_boxes', [])\n",
    "        \n",
    "        # Transform word boxes to the required format\n",
    "        transformed_words = []\n",
    "        for word_box in word_boxes:\n",
    "            # Ensure we have the required fields\n",
    "            text = word_box.get('text', '').strip()\n",
    "            if not text:  # Skip empty text\n",
    "                continue\n",
    "                \n",
    "            # Get bounding box coordinates\n",
    "            x0 = word_box.get('x0', 0)\n",
    "            y0 = word_box.get('y0', 0)\n",
    "            x1 = word_box.get('x1', 0)\n",
    "            y1 = word_box.get('y1', 0)\n",
    "            \n",
    "            # Normalize coordinates to 0-1000 range (LayoutLMv3 standard)\n",
    "            # This assumes the original coordinates are in points/pixels\n",
    "            normalized_bbox = [\n",
    "                min(1000, max(0, int((x0 / page_width) * 1000))),\n",
    "                min(1000, max(0, int((y0 / page_height) * 1000))),\n",
    "                min(1000, max(0, int((x1 / page_width) * 1000))),\n",
    "                min(1000, max(0, int((y1 / page_height) * 1000)))\n",
    "            ]\n",
    "            \n",
    "            # Create word entry matching the schema\n",
    "            word_entry = {\n",
    "                \"text\": text,\n",
    "                \"bbox\": normalized_bbox\n",
    "            }\n",
    "            \n",
    "            transformed_words.append(word_entry)\n",
    "        \n",
    "        # Create page layout entry matching the schema\n",
    "        page_entry = {\n",
    "            \"page_number\": page_number,\n",
    "            \"page_width\": float(page_width),\n",
    "            \"page_height\": float(page_height),\n",
    "            \"words\": transformed_words\n",
    "        }\n",
    "        \n",
    "        layoutlmv3_data[\"page_layouts\"].append(page_entry)\n",
    "    \n",
    "    # Print transformation summary\n",
    "    total_words = sum(len(page[\"words\"]) for page in layoutlmv3_data[\"page_layouts\"])\n",
    "    print(f\"🔄 Transformed {len(layoutlmv3_data['page_layouts'])} pages with {total_words} words to LayoutLMv3 format\")\n",
    "    \n",
    "    return layoutlmv3_data\n",
    "\n",
    "\n",
    "def validate_layoutlmv3_schema(data):\n",
    "    \"\"\"\n",
    "    Validate that the data matches the LayoutLMv3 schema requirements.\n",
    "    \n",
    "    Args:\n",
    "        data (dict): Data to validate\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (is_valid, validation_errors)\n",
    "    \"\"\"\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    # Check top-level structure\n",
    "    if not isinstance(data, dict):\n",
    "        errors.append(\"Data must be a dictionary\")\n",
    "        return False, errors\n",
    "    \n",
    "    # Check required top-level fields\n",
    "    required_fields = ['file_info', 'page_layouts']\n",
    "    for field in required_fields:\n",
    "        if field not in data:\n",
    "            errors.append(f\"Missing required field: {field}\")\n",
    "    \n",
    "    # Validate file_info\n",
    "    file_info = data.get('file_info', {})\n",
    "    if not isinstance(file_info, dict):\n",
    "        errors.append(\"file_info must be a dictionary\")\n",
    "    else:\n",
    "        if 'filename' not in file_info:\n",
    "            errors.append(\"file_info missing required field: filename\")\n",
    "        if 'total_pages' not in file_info:\n",
    "            errors.append(\"file_info missing required field: total_pages\")\n",
    "        elif not isinstance(file_info['total_pages'], (int, float)):\n",
    "            errors.append(\"file_info.total_pages must be a number\")\n",
    "    \n",
    "    # Validate page_layouts\n",
    "    page_layouts = data.get('page_layouts', [])\n",
    "    if not isinstance(page_layouts, list):\n",
    "        errors.append(\"page_layouts must be an array\")\n",
    "    else:\n",
    "        for i, page in enumerate(page_layouts):\n",
    "            if not isinstance(page, dict):\n",
    "                errors.append(f\"page_layouts[{i}] must be a dictionary\")\n",
    "                continue\n",
    "            \n",
    "            # Check required page fields\n",
    "            page_required = ['page_number', 'page_width', 'page_height', 'words']\n",
    "            for field in page_required:\n",
    "                if field not in page:\n",
    "                    errors.append(f\"page_layouts[{i}] missing required field: {field}\")\n",
    "            \n",
    "            # Validate words array\n",
    "            words = page.get('words', [])\n",
    "            if not isinstance(words, list):\n",
    "                errors.append(f\"page_layouts[{i}].words must be an array\")\n",
    "            else:\n",
    "                for j, word in enumerate(words):\n",
    "                    if not isinstance(word, dict):\n",
    "                        errors.append(f\"page_layouts[{i}].words[{j}] must be a dictionary\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Check required word fields\n",
    "                    if 'text' not in word:\n",
    "                        errors.append(f\"page_layouts[{i}].words[{j}] missing required field: text\")\n",
    "                    if 'bbox' not in word:\n",
    "                        errors.append(f\"page_layouts[{i}].words[{j}] missing required field: bbox\")\n",
    "                    else:\n",
    "                        bbox = word['bbox']\n",
    "                        if not isinstance(bbox, list) or len(bbox) != 4:\n",
    "                            errors.append(f\"page_layouts[{i}].words[{j}].bbox must be an array of 4 numbers\")\n",
    "                        elif not all(isinstance(x, (int, float)) for x in bbox):\n",
    "                            errors.append(f\"page_layouts[{i}].words[{j}].bbox must contain only numbers\")\n",
    "    \n",
    "    is_valid = len(errors) == 0\n",
    "    return is_valid, errors\n",
    "\n",
    "\n",
    "def save_layoutlmv3_output(data, output_file=None, validate=True):\n",
    "    \"\"\"\n",
    "    Save data in LayoutLMv3 format with optional validation.\n",
    "    \n",
    "    Args:\n",
    "        data (dict): Data to save\n",
    "        output_file (str, optional): Output file path\n",
    "        validate (bool): Whether to validate schema before saving\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to saved file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate if requested\n",
    "    if validate:\n",
    "        is_valid, errors = validate_layoutlmv3_schema(data)\n",
    "        if not is_valid:\n",
    "            print(\"❌ Schema validation failed:\")\n",
    "            for error in errors:\n",
    "                print(f\"  - {error}\")\n",
    "            raise ValueError(\"Data does not match LayoutLMv3 schema\")\n",
    "        else:\n",
    "            print(\"✅ Schema validation passed\")\n",
    "    \n",
    "    # Determine output file path\n",
    "    if output_file is None:\n",
    "        # Create default output file name\n",
    "        filename = data.get('file_info', {}).get('filename', 'unknown')\n",
    "        base_name = filename.replace('.pdf', '').replace('.txt', '')\n",
    "        output_file = f\"../data/parsed/layoutlmv3_{base_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    \n",
    "    # Save the data\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"💾 LayoutLMv3 data saved to: {output_file}\")\n",
    "    return output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic usage - Filter most recent layout file to LayoutLMv3 format\n",
    "print(\"🔄 Example 1: Converting most recent layout file to LayoutLMv3 format\")\n",
    "try:\n",
    "    layoutlmv3_output = end(output_filter=\"layout\")\n",
    "    print(f\"✅ Successfully transformed data with {len(layoutlmv3_output['page_layouts'])} pages\")\n",
    "    print(f\"📊 Total words across all pages: {sum(len(page['words']) for page in layoutlmv3_output['page_layouts'])}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Example 2: Specify a specific layout file\n",
    "print(\"🔄 Example 2: Converting specific layout file to LayoutLMv3 format\")\n",
    "try:\n",
    "    # You can specify a specific layout file path\n",
    "    specific_layout_file = \"../data/parsed/MSFT/2022/MSFT_10-K_20220728_000156459022026876_layout.json\"\n",
    "    if os.path.exists(specific_layout_file):\n",
    "        layoutlmv3_output = end(\n",
    "            output_filter=\"layout\", \n",
    "            input_data=specific_layout_file,\n",
    "            output_file=\"../data/parsed/example_layoutlmv3_output.json\"\n",
    "        )\n",
    "        print(f\"✅ Successfully converted specific file\")\n",
    "        print(f\"📁 Output saved to: ../data/parsed/example_layoutlmv3_output.json\")\n",
    "    else:\n",
    "        print(\"⚠️  Specific layout file not found, skipping this example\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Example 3: Return original data without filtering\n",
    "print(\"🔄 Example 3: Return original data without filtering\")\n",
    "try:\n",
    "    original_data = end()  # No filter specified\n",
    "    print(f\"✅ Retrieved original data structure\")\n",
    "    print(f\"📋 Available keys: {list(original_data.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded3baa",
   "metadata": {},
   "source": [
    "## Integration with Main Processing Pipeline\n",
    "\n",
    "To automatically generate LayoutLMv3-compatible output during the main PDF processing, you can modify the `process_single_pdf` function to include the `end()` function call. Here's how to integrate it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f059b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Found 3 PDF files to process\n",
      "\n",
      "📄 Processing: MSFT_10-K_20230727_000095017023035122.pdf\n",
      "📅 Year: 2023\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2023/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2023/tables/integrated_table_11.csv\n",
      "Exported integrated table 12 to ../data/parsed/MSFT/2023/tables/integrated_table_12.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2023/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2023/tables/integrated_table_11.csv\n",
      "Exported integrated table 12 to ../data/parsed/MSFT/2023/tables/integrated_table_12.csv\n",
      "Exported integrated table 13 to ../data/parsed/MSFT/2023/tables/integrated_table_13.csv\n",
      "Exported integrated table 14 to ../data/parsed/MSFT/2023/tables/integrated_table_14.csv\n",
      "Exported integrated table 15 to ../data/parsed/MSFT/2023/tables/integrated_table_15.csv\n",
      "Exported integrated table 16 to ../data/parsed/MSFT/2023/tables/integrated_table_16.csv\n",
      "Exported integrated table 17 to ../data/parsed/MSFT/2023/tables/integrated_table_17.csv\n",
      "Exported integrated table 18 to ../data/parsed/MSFT/2023/tables/integrated_table_18.csv\n",
      "Exported integrated table 19 to ../data/parsed/MSFT/2023/tables/integrated_table_19.csv\n",
      "Exported integrated table 20 to ../data/parsed/MSFT/2023/tables/integrated_table_20.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2023/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2023/tables/integrated_table_11.csv\n",
      "Exported integrated table 12 to ../data/parsed/MSFT/2023/tables/integrated_table_12.csv\n",
      "Exported integrated table 13 to ../data/parsed/MSFT/2023/tables/integrated_table_13.csv\n",
      "Exported integrated table 14 to ../data/parsed/MSFT/2023/tables/integrated_table_14.csv\n",
      "Exported integrated table 15 to ../data/parsed/MSFT/2023/tables/integrated_table_15.csv\n",
      "Exported integrated table 16 to ../data/parsed/MSFT/2023/tables/integrated_table_16.csv\n",
      "Exported integrated table 17 to ../data/parsed/MSFT/2023/tables/integrated_table_17.csv\n",
      "Exported integrated table 18 to ../data/parsed/MSFT/2023/tables/integrated_table_18.csv\n",
      "Exported integrated table 19 to ../data/parsed/MSFT/2023/tables/integrated_table_19.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2023/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2023/tables/integrated_table_11.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2023/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2023/tables/integrated_table_11.csv\n",
      "Exported integrated table 12 to ../data/parsed/MSFT/2023/tables/integrated_table_12.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2023/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2023/tables/integrated_table_11.csv\n",
      "Exported integrated table 12 to ../data/parsed/MSFT/2023/tables/integrated_table_12.csv\n",
      "Exported integrated table 13 to ../data/parsed/MSFT/2023/tables/integrated_table_13.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2023/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2023/tables/integrated_table_11.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2023/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2023/tables/integrated_table_11.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2023/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2023/tables/integrated_table_11.csv\n",
      "Exported integrated table 12 to ../data/parsed/MSFT/2023/tables/integrated_table_12.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2023/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2023/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2023/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2023/tables/integrated_table_11.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2023/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2023/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2023/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2023/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2023/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2023/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2023/tables/integrated_table_7.csv\n",
      "  📄 Total pages: 117\n",
      "      🔍 Page 1 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 1 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 1: Trying character-based extraction...\n",
      "      ✅ Page 1: Character-based extraction found 123 words\n",
      "      🔍 Page 2 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 2 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 2: Trying character-based extraction...\n",
      "      ✅ Page 2: Character-based extraction found 3 words\n",
      "      🔍 Page 3 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 3 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 3: Trying character-based extraction...\n",
      "      ✅ Page 3: Character-based extraction found 110 words\n",
      "      🔍 Page 4 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 4 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 4: Trying character-based extraction...\n",
      "      ✅ Page 4: Character-based extraction found 78 words\n",
      "      🔍 Page 5 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 5 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 5: Trying character-based extraction...\n",
      "      ✅ Page 5: Character-based extraction found 164 words\n",
      "      🔍 Page 6 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 6 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 6: Trying character-based extraction...\n",
      "      ✅ Page 6: Character-based extraction found 311 words\n",
      "      🔍 Page 7 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 7 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 7: Trying character-based extraction...\n",
      "      ✅ Page 7: Character-based extraction found 221 words\n",
      "      🔍 Page 8 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 8 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 8: Trying character-based extraction...\n",
      "      ✅ Page 8: Character-based extraction found 215 words\n",
      "      🔍 Page 9 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 9 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 9: Trying character-based extraction...\n",
      "      ✅ Page 9: Character-based extraction found 200 words\n",
      "      🔍 Page 10 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 10 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 10: Trying character-based extraction...\n",
      "      ✅ Page 10: Character-based extraction found 177 words\n",
      "      🔍 Page 11 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 11 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 11: Trying character-based extraction...\n",
      "      ✅ Page 11: Character-based extraction found 222 words\n",
      "      🔍 Page 12 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 12 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 12: Trying character-based extraction...\n",
      "      ✅ Page 12: Character-based extraction found 188 words\n",
      "      🔍 Page 13 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 13 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 13: Trying character-based extraction...\n",
      "      ✅ Page 13: Character-based extraction found 301 words\n",
      "      🔍 Page 14 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 14 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 14: Trying character-based extraction...\n",
      "      ✅ Page 14: Character-based extraction found 229 words\n",
      "      🔍 Page 15 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 15 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 15: Trying character-based extraction...\n",
      "      ✅ Page 15: Character-based extraction found 220 words\n",
      "      🔍 Page 16 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 16 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 16: Trying character-based extraction...\n",
      "      ✅ Page 16: Character-based extraction found 232 words\n",
      "      🔍 Page 17 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 17 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 17: Trying character-based extraction...\n",
      "      ✅ Page 17: Character-based extraction found 175 words\n",
      "      🔍 Page 18 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 18 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 18: Trying character-based extraction...\n",
      "      ✅ Page 18: Character-based extraction found 275 words\n",
      "      🔍 Page 19 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 19 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 19: Trying character-based extraction...\n",
      "      ✅ Page 19: Character-based extraction found 298 words\n",
      "      🔍 Page 20 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 20 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 20: Trying character-based extraction...\n",
      "      ✅ Page 20: Character-based extraction found 209 words\n",
      "    📖 Processed 20 pages...\n",
      "      🔍 Page 21 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 21 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 21: Trying character-based extraction...\n",
      "      ✅ Page 21: Character-based extraction found 118 words\n",
      "      🔍 Page 22 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 22 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 22: Trying character-based extraction...\n",
      "      ✅ Page 22: Character-based extraction found 103 words\n",
      "      🔍 Page 23 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 23 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 23: Trying character-based extraction...\n",
      "      ✅ Page 23: Character-based extraction found 101 words\n",
      "      🔍 Page 24 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 24 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 24: Trying character-based extraction...\n",
      "      ✅ Page 24: Character-based extraction found 238 words\n",
      "      🔍 Page 25 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 25 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 25: Trying character-based extraction...\n",
      "      ✅ Page 25: Character-based extraction found 292 words\n",
      "      🔍 Page 26 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 26 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 26: Trying character-based extraction...\n",
      "      ✅ Page 26: Character-based extraction found 294 words\n",
      "      🔍 Page 27 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 27 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 27: Trying character-based extraction...\n",
      "      ✅ Page 27: Character-based extraction found 305 words\n",
      "      🔍 Page 28 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 28 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 28: Trying character-based extraction...\n",
      "      ✅ Page 28: Character-based extraction found 294 words\n",
      "      🔍 Page 29 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 29 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 29: Trying character-based extraction...\n",
      "      ✅ Page 29: Character-based extraction found 220 words\n",
      "      🔍 Page 30 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 30 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 30: Trying character-based extraction...\n",
      "      ✅ Page 30: Character-based extraction found 181 words\n",
      "      🔍 Page 31 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 31 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 31: Trying character-based extraction...\n",
      "      ✅ Page 31: Character-based extraction found 254 words\n",
      "      🔍 Page 32 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 32 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 32: Trying character-based extraction...\n",
      "      ✅ Page 32: Character-based extraction found 260 words\n",
      "      🔍 Page 33 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 33 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 33: Trying character-based extraction...\n",
      "      ✅ Page 33: Character-based extraction found 272 words\n",
      "      🔍 Page 34 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 34 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 34: Trying character-based extraction...\n",
      "      ✅ Page 34: Character-based extraction found 251 words\n",
      "      🔍 Page 35 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 35 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 35: Trying character-based extraction...\n",
      "      ✅ Page 35: Character-based extraction found 185 words\n",
      "      🔍 Page 36 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 36 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 36: Trying character-based extraction...\n",
      "      ✅ Page 36: Character-based extraction found 168 words\n",
      "      🔍 Page 37 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 37 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 37: Trying character-based extraction...\n",
      "      ✅ Page 37: Character-based extraction found 135 words\n",
      "      🔍 Page 38 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 38 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 38: Trying character-based extraction...\n",
      "      ✅ Page 38: Character-based extraction found 95 words\n",
      "      🔍 Page 39 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 39 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 39: Trying character-based extraction...\n",
      "      ✅ Page 39: Character-based extraction found 88 words\n",
      "    ⚠️  Page 40: Poor pdfplumber extraction (36 chars), trying OCR...\n",
      "      📝 OCR extracted 8 word boxes from page 40\n",
      "      ✅ Page 40: Extracted 8 word boxes\n",
      "    📖 Processed 40 pages...\n",
      "      🔍 Page 41 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 41 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 41: Trying character-based extraction...\n",
      "      ✅ Page 41: Character-based extraction found 143 words\n",
      "      🔍 Page 42 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 42 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 42: Trying character-based extraction...\n",
      "      ✅ Page 42: Character-based extraction found 221 words\n",
      "      🔍 Page 43 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 43 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 43: Trying character-based extraction...\n",
      "      ✅ Page 43: Character-based extraction found 161 words\n",
      "      🔍 Page 44 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 44 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 44: Trying character-based extraction...\n",
      "      ✅ Page 44: Character-based extraction found 255 words\n",
      "      🔍 Page 45 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 45 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 45: Trying character-based extraction...\n",
      "      ✅ Page 45: Character-based extraction found 198 words\n",
      "      🔍 Page 46 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 46 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 46: Trying character-based extraction...\n",
      "      ✅ Page 46: Character-based extraction found 165 words\n",
      "      🔍 Page 47 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 47 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 47: Trying character-based extraction...\n",
      "      ✅ Page 47: Character-based extraction found 81 words\n",
      "      🔍 Page 48 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 48 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 48: Trying character-based extraction...\n",
      "      ✅ Page 48: Character-based extraction found 194 words\n",
      "      🔍 Page 49 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 49 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 49: Trying character-based extraction...\n",
      "      ✅ Page 49: Character-based extraction found 131 words\n",
      "      🔍 Page 50 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 50 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 50: Trying character-based extraction...\n",
      "      ✅ Page 50: Character-based extraction found 182 words\n",
      "      🔍 Page 51 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 51 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 51: Trying character-based extraction...\n",
      "      ✅ Page 51: Character-based extraction found 248 words\n",
      "      🔍 Page 52 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 52 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 52: Trying character-based extraction...\n",
      "      ✅ Page 52: Character-based extraction found 183 words\n",
      "      🔍 Page 53 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 53 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 53: Trying character-based extraction...\n",
      "      ✅ Page 53: Character-based extraction found 185 words\n",
      "      🔍 Page 54 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 54 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 54: Trying character-based extraction...\n",
      "      ✅ Page 54: Character-based extraction found 214 words\n",
      "      🔍 Page 55 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 55 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 55: Trying character-based extraction...\n",
      "      ✅ Page 55: Character-based extraction found 132 words\n",
      "      🔍 Page 56 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 56 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 56: Trying character-based extraction...\n",
      "      ✅ Page 56: Character-based extraction found 104 words\n",
      "      🔍 Page 57 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 57 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 57: Trying character-based extraction...\n",
      "      ✅ Page 57: Character-based extraction found 121 words\n",
      "      🔍 Page 58 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 58 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 58: Trying character-based extraction...\n",
      "      ✅ Page 58: Character-based extraction found 95 words\n",
      "      🔍 Page 59 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 59 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 59: Trying character-based extraction...\n",
      "      ✅ Page 59: Character-based extraction found 103 words\n",
      "      🔍 Page 60 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 60 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 60: Trying character-based extraction...\n",
      "      ✅ Page 60: Character-based extraction found 41 words\n",
      "    📖 Processed 60 pages...\n",
      "      🔍 Page 61 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 61 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 61: Trying character-based extraction...\n",
      "      ✅ Page 61: Character-based extraction found 123 words\n",
      "      🔍 Page 62 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 62 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 62: Trying character-based extraction...\n",
      "      ✅ Page 62: Character-based extraction found 157 words\n",
      "      🔍 Page 63 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 63 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 63: Trying character-based extraction...\n",
      "      ✅ Page 63: Character-based extraction found 93 words\n",
      "      🔍 Page 64 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 64 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 64: Trying character-based extraction...\n",
      "      ✅ Page 64: Character-based extraction found 228 words\n",
      "      🔍 Page 65 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 65 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 65: Trying character-based extraction...\n",
      "      ✅ Page 65: Character-based extraction found 291 words\n",
      "      🔍 Page 66 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 66 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 66: Trying character-based extraction...\n",
      "      ✅ Page 66: Character-based extraction found 166 words\n",
      "      🔍 Page 67 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 67 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 67: Trying character-based extraction...\n",
      "      ✅ Page 67: Character-based extraction found 233 words\n",
      "      🔍 Page 68 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 68 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 68: Trying character-based extraction...\n",
      "      ✅ Page 68: Character-based extraction found 226 words\n",
      "      🔍 Page 69 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 69 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 69: Trying character-based extraction...\n",
      "      ✅ Page 69: Character-based extraction found 125 words\n",
      "      🔍 Page 70 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 70 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 70: Trying character-based extraction...\n",
      "      ✅ Page 70: Character-based extraction found 223 words\n",
      "      🔍 Page 71 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 71 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 71: Trying character-based extraction...\n",
      "      ✅ Page 71: Character-based extraction found 220 words\n",
      "      🔍 Page 72 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 72 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 72: Trying character-based extraction...\n",
      "      ✅ Page 72: Character-based extraction found 101 words\n",
      "      🔍 Page 73 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 73 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 73: Trying character-based extraction...\n",
      "      ✅ Page 73: Character-based extraction found 224 words\n",
      "      🔍 Page 74 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 74 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 74: Trying character-based extraction...\n",
      "      ✅ Page 74: Character-based extraction found 260 words\n",
      "      🔍 Page 75 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 75 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 75: Trying character-based extraction...\n",
      "      ✅ Page 75: Character-based extraction found 205 words\n",
      "      🔍 Page 76 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 76 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 76: Trying character-based extraction...\n",
      "      ✅ Page 76: Character-based extraction found 188 words\n",
      "      🔍 Page 77 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 77 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 77: Trying character-based extraction...\n",
      "      ✅ Page 77: Character-based extraction found 182 words\n",
      "    ⚠️  Page 78: Poor pdfplumber extraction (2 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 78\n",
      "      ✅ Page 78: Extracted 1 word boxes\n",
      "      🔍 Page 79 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 79 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 79: Trying character-based extraction...\n",
      "      ✅ Page 79: Character-based extraction found 105 words\n",
      "      🔍 Page 80 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 80 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 80: Trying character-based extraction...\n",
      "      ✅ Page 80: Character-based extraction found 105 words\n",
      "    📖 Processed 80 pages...\n",
      "      🔍 Page 81 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 81 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 81: Trying character-based extraction...\n",
      "      ✅ Page 81: Character-based extraction found 213 words\n",
      "    ⚠️  Page 82: Poor pdfplumber extraction (2 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 82\n",
      "      ✅ Page 82: Extracted 1 word boxes\n",
      "      🔍 Page 83 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 83 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 83: Trying character-based extraction...\n",
      "      ✅ Page 83: Character-based extraction found 190 words\n",
      "      🔍 Page 84 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 84 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 84: Trying character-based extraction...\n",
      "      ✅ Page 84: Character-based extraction found 183 words\n",
      "      🔍 Page 85 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 85 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 85: Trying character-based extraction...\n",
      "      ✅ Page 85: Character-based extraction found 3 words\n",
      "      🔍 Page 86 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 86 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 86: Trying character-based extraction...\n",
      "      ✅ Page 86: Character-based extraction found 79 words\n",
      "      🔍 Page 87 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 87 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 87: Trying character-based extraction...\n",
      "      ✅ Page 87: Character-based extraction found 190 words\n",
      "      🔍 Page 88 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 88 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 88: Trying character-based extraction...\n",
      "      ✅ Page 88: Character-based extraction found 137 words\n",
      "    ⚠️  Page 89: Poor pdfplumber extraction (2 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 89\n",
      "      ✅ Page 89: Extracted 1 word boxes\n",
      "      🔍 Page 90 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 90 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 90: Trying character-based extraction...\n",
      "      ✅ Page 90: Character-based extraction found 149 words\n",
      "      🔍 Page 91 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 91 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 91: Trying character-based extraction...\n",
      "      ✅ Page 91: Character-based extraction found 135 words\n",
      "    ⚠️  Page 92: Poor pdfplumber extraction (2 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 92\n",
      "      ✅ Page 92: Extracted 1 word boxes\n",
      "      🔍 Page 93 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 93 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 93: Trying character-based extraction...\n",
      "      ✅ Page 93: Character-based extraction found 124 words\n",
      "      🔍 Page 94 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 94 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 94: Trying character-based extraction...\n",
      "      ✅ Page 94: Character-based extraction found 240 words\n",
      "      🔍 Page 95 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 95 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 95: Trying character-based extraction...\n",
      "      ✅ Page 95: Character-based extraction found 115 words\n",
      "      🔍 Page 96 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 96 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 96: Trying character-based extraction...\n",
      "      ✅ Page 96: Character-based extraction found 99 words\n",
      "      🔍 Page 97 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 97 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 97: Trying character-based extraction...\n",
      "      ✅ Page 97: Character-based extraction found 164 words\n",
      "      🔍 Page 98 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 98 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 98: Trying character-based extraction...\n",
      "      ✅ Page 98: Character-based extraction found 4 words\n",
      "      🔍 Page 99 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 99 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 99: Trying character-based extraction...\n",
      "      ✅ Page 99: Character-based extraction found 115 words\n",
      "      🔍 Page 100 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 100 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 100: Trying character-based extraction...\n",
      "      ✅ Page 100: Character-based extraction found 217 words\n",
      "    📖 Processed 100 pages...\n",
      "      🔍 Page 101 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 101 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 101: Trying character-based extraction...\n",
      "      ✅ Page 101: Character-based extraction found 191 words\n",
      "      🔍 Page 102 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 102 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 102: Trying character-based extraction...\n",
      "      ✅ Page 102: Character-based extraction found 157 words\n",
      "      🔍 Page 103 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 103 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 103: Trying character-based extraction...\n",
      "      ✅ Page 103: Character-based extraction found 222 words\n",
      "      🔍 Page 104 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 104 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 104: Trying character-based extraction...\n",
      "      ✅ Page 104: Character-based extraction found 243 words\n",
      "      🔍 Page 105 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 105 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 105: Trying character-based extraction...\n",
      "      ✅ Page 105: Character-based extraction found 64 words\n",
      "      🔍 Page 106 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 106 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 106: Trying character-based extraction...\n",
      "      ✅ Page 106: Character-based extraction found 96 words\n",
      "      🔍 Page 107 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 107 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 107: Trying character-based extraction...\n",
      "      ✅ Page 107: Character-based extraction found 224 words\n",
      "      🔍 Page 108 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 108 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 108: Trying character-based extraction...\n",
      "      ✅ Page 108: Character-based extraction found 134 words\n",
      "      🔍 Page 109 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 109 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 109: Trying character-based extraction...\n",
      "      ✅ Page 109: Character-based extraction found 107 words\n",
      "      🔍 Page 110 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 110 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 110: Trying character-based extraction...\n",
      "      ✅ Page 110: Character-based extraction found 81 words\n",
      "      🔍 Page 111 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 111 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 111: Trying character-based extraction...\n",
      "      ✅ Page 111: Character-based extraction found 90 words\n",
      "      🔍 Page 112 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 112 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 112: Trying character-based extraction...\n",
      "      ✅ Page 112: Character-based extraction found 102 words\n",
      "    ⚠️  Page 113: Poor pdfplumber extraction (90 chars), trying OCR...\n",
      "      📝 OCR extracted 12 word boxes from page 113\n",
      "      ✅ Page 113: Extracted 12 word boxes\n",
      "      🔍 Page 114 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 114 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 114: Trying character-based extraction...\n",
      "      ✅ Page 114: Character-based extraction found 150 words\n",
      "      🔍 Page 115 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 115 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 115: Trying character-based extraction...\n",
      "      ✅ Page 115: Character-based extraction found 105 words\n",
      "    ⚠️  Page 116: Poor pdfplumber extraction (52 chars), trying OCR...\n",
      "      📝 OCR extracted 11 word boxes from page 116\n",
      "      ✅ Page 116: Extracted 11 word boxes\n",
      "      🔍 Page 117 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 117 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 117: Trying character-based extraction...\n",
      "      ✅ Page 117: Character-based extraction found 124 words\n",
      "  ✅ Saved: MSFT_10-K_20230727_000095017023035122_extracted.txt\n",
      "  �� Quality: 110/117 pages via pdfplumber\n",
      "  📦 Saved word boxes: MSFT_10-K_20230727_000095017023035122_wordboxes.json\n",
      "  📐 Saved layout data: MSFT_10-K_20230727_000095017023035122_layout.json\n",
      "  📊 Total word boxes: 18899\n",
      "\n",
      "📄 Processing: MSFT_10-K_20240730_000095017024087843.pdf\n",
      "📅 Year: 2024\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2024/tables/integrated_table_11.csv\n",
      "Exported integrated table 12 to ../data/parsed/MSFT/2024/tables/integrated_table_12.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2024/tables/integrated_table_11.csv\n",
      "Exported integrated table 12 to ../data/parsed/MSFT/2024/tables/integrated_table_12.csv\n",
      "Exported integrated table 13 to ../data/parsed/MSFT/2024/tables/integrated_table_13.csv\n",
      "Exported integrated table 14 to ../data/parsed/MSFT/2024/tables/integrated_table_14.csv\n",
      "Exported integrated table 15 to ../data/parsed/MSFT/2024/tables/integrated_table_15.csv\n",
      "Exported integrated table 16 to ../data/parsed/MSFT/2024/tables/integrated_table_16.csv\n",
      "Exported integrated table 17 to ../data/parsed/MSFT/2024/tables/integrated_table_17.csv\n",
      "Exported integrated table 18 to ../data/parsed/MSFT/2024/tables/integrated_table_18.csv\n",
      "Exported integrated table 19 to ../data/parsed/MSFT/2024/tables/integrated_table_19.csv\n",
      "Exported integrated table 20 to ../data/parsed/MSFT/2024/tables/integrated_table_20.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2024/tables/integrated_table_11.csv\n",
      "Exported integrated table 12 to ../data/parsed/MSFT/2024/tables/integrated_table_12.csv\n",
      "Exported integrated table 13 to ../data/parsed/MSFT/2024/tables/integrated_table_13.csv\n",
      "Exported integrated table 14 to ../data/parsed/MSFT/2024/tables/integrated_table_14.csv\n",
      "Exported integrated table 15 to ../data/parsed/MSFT/2024/tables/integrated_table_15.csv\n",
      "Exported integrated table 16 to ../data/parsed/MSFT/2024/tables/integrated_table_16.csv\n",
      "Exported integrated table 17 to ../data/parsed/MSFT/2024/tables/integrated_table_17.csv\n",
      "Exported integrated table 18 to ../data/parsed/MSFT/2024/tables/integrated_table_18.csv\n",
      "Exported integrated table 19 to ../data/parsed/MSFT/2024/tables/integrated_table_19.csv\n",
      "Exported integrated table 20 to ../data/parsed/MSFT/2024/tables/integrated_table_20.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2024/tables/integrated_table_11.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2024/tables/integrated_table_11.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2024/tables/integrated_table_11.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2024/tables/integrated_table_11.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2024/tables/integrated_table_11.csv\n",
      "Exported integrated table 12 to ../data/parsed/MSFT/2024/tables/integrated_table_12.csv\n",
      "Exported integrated table 13 to ../data/parsed/MSFT/2024/tables/integrated_table_13.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2024/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2024/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2024/tables/integrated_table_9.csv\n",
      "Exported integrated table 10 to ../data/parsed/MSFT/2024/tables/integrated_table_10.csv\n",
      "Exported integrated table 11 to ../data/parsed/MSFT/2024/tables/integrated_table_11.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2024/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2024/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2024/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2024/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2024/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2024/tables/integrated_table_6.csv\n",
      "  📄 Total pages: 125\n",
      "      🔍 Page 1 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 1 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 1: Trying character-based extraction...\n",
      "      ✅ Page 1: Character-based extraction found 89 words\n",
      "    ⚠️  Page 2: Poor pdfplumber extraction (0 chars), trying OCR...\n",
      "      📝 OCR extracted 0 word boxes from page 2\n",
      "      ✅ Page 2: Extracted 0 word boxes\n",
      "      🔍 Page 3 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 3 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 3: Trying character-based extraction...\n",
      "      ✅ Page 3: Character-based extraction found 124 words\n",
      "    ⚠️  Page 4: Poor pdfplumber extraction (16 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 4\n",
      "      ✅ Page 4: Extracted 1 word boxes\n",
      "      🔍 Page 5 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 5 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 5: Trying character-based extraction...\n",
      "      ✅ Page 5: Character-based extraction found 122 words\n",
      "      🔍 Page 6 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 6 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 6: Trying character-based extraction...\n",
      "      ✅ Page 6: Character-based extraction found 179 words\n",
      "      🔍 Page 7 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 7 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 7: Trying character-based extraction...\n",
      "      ✅ Page 7: Character-based extraction found 110 words\n",
      "      🔍 Page 8 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 8 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 8: Trying character-based extraction...\n",
      "      ✅ Page 8: Character-based extraction found 160 words\n",
      "      🔍 Page 9 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 9 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 9: Trying character-based extraction...\n",
      "      ✅ Page 9: Character-based extraction found 115 words\n",
      "      🔍 Page 10 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 10 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 10: Trying character-based extraction...\n",
      "      ✅ Page 10: Character-based extraction found 150 words\n",
      "      🔍 Page 11 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 11 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 11: Trying character-based extraction...\n",
      "      ✅ Page 11: Character-based extraction found 74 words\n",
      "      🔍 Page 12 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 12 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 12: Trying character-based extraction...\n",
      "      ✅ Page 12: Character-based extraction found 112 words\n",
      "      🔍 Page 13 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 13 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 13: Trying character-based extraction...\n",
      "      ✅ Page 13: Character-based extraction found 105 words\n",
      "      🔍 Page 14 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 14 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 14: Trying character-based extraction...\n",
      "      ✅ Page 14: Character-based extraction found 98 words\n",
      "      🔍 Page 15 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 15 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 15: Trying character-based extraction...\n",
      "      ✅ Page 15: Character-based extraction found 124 words\n",
      "      🔍 Page 16 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 16 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 16: Trying character-based extraction...\n",
      "      ✅ Page 16: Character-based extraction found 147 words\n",
      "      🔍 Page 17 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 17 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 17: Trying character-based extraction...\n",
      "      ✅ Page 17: Character-based extraction found 65 words\n",
      "      🔍 Page 18 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 18 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 18: Trying character-based extraction...\n",
      "      ✅ Page 18: Character-based extraction found 113 words\n",
      "      🔍 Page 19 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 19 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 19: Trying character-based extraction...\n",
      "      ✅ Page 19: Character-based extraction found 81 words\n",
      "      🔍 Page 20 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 20 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 20: Trying character-based extraction...\n",
      "      ✅ Page 20: Character-based extraction found 136 words\n",
      "    📖 Processed 20 pages...\n",
      "      🔍 Page 21 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 21 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 21: Trying character-based extraction...\n",
      "      ✅ Page 21: Character-based extraction found 112 words\n",
      "      🔍 Page 22 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 22 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 22: Trying character-based extraction...\n",
      "      ✅ Page 22: Character-based extraction found 127 words\n",
      "      🔍 Page 23 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 23 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 23: Trying character-based extraction...\n",
      "      ✅ Page 23: Character-based extraction found 161 words\n",
      "      🔍 Page 24 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 24 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 24: Trying character-based extraction...\n",
      "      ✅ Page 24: Character-based extraction found 145 words\n",
      "      🔍 Page 25 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 25 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 25: Trying character-based extraction...\n",
      "      ✅ Page 25: Character-based extraction found 107 words\n",
      "      🔍 Page 26 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 26 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 26: Trying character-based extraction...\n",
      "      ✅ Page 26: Character-based extraction found 142 words\n",
      "      🔍 Page 27 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 27 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 27: Trying character-based extraction...\n",
      "      ✅ Page 27: Character-based extraction found 98 words\n",
      "      🔍 Page 28 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 28 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 28: Trying character-based extraction...\n",
      "      ✅ Page 28: Character-based extraction found 145 words\n",
      "      🔍 Page 29 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 29 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 29: Trying character-based extraction...\n",
      "      ✅ Page 29: Character-based extraction found 182 words\n",
      "      🔍 Page 30 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 30 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 30: Trying character-based extraction...\n",
      "      ✅ Page 30: Character-based extraction found 160 words\n",
      "      🔍 Page 31 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 31 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 31: Trying character-based extraction...\n",
      "      ✅ Page 31: Character-based extraction found 165 words\n",
      "      🔍 Page 32 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 32 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 32: Trying character-based extraction...\n",
      "      ✅ Page 32: Character-based extraction found 146 words\n",
      "      🔍 Page 33 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 33 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 33: Trying character-based extraction...\n",
      "      ✅ Page 33: Character-based extraction found 146 words\n",
      "      🔍 Page 34 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 34 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 34: Trying character-based extraction...\n",
      "      ✅ Page 34: Character-based extraction found 163 words\n",
      "      🔍 Page 35 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 35 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 35: Trying character-based extraction...\n",
      "      ✅ Page 35: Character-based extraction found 119 words\n",
      "      🔍 Page 36 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 36 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 36: Trying character-based extraction...\n",
      "      ✅ Page 36: Character-based extraction found 169 words\n",
      "      🔍 Page 37 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 37 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 37: Trying character-based extraction...\n",
      "      ✅ Page 37: Character-based extraction found 115 words\n",
      "      🔍 Page 38 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 38 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 38: Trying character-based extraction...\n",
      "      ✅ Page 38: Character-based extraction found 56 words\n",
      "      🔍 Page 39 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 39 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 39: Trying character-based extraction...\n",
      "      ✅ Page 39: Character-based extraction found 68 words\n",
      "    ⚠️  Page 40: Poor pdfplumber extraction (36 chars), trying OCR...\n",
      "      📝 OCR extracted 8 word boxes from page 40\n",
      "      ✅ Page 40: Extracted 8 word boxes\n",
      "    📖 Processed 40 pages...\n",
      "      🔍 Page 41 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 41 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 41: Trying character-based extraction...\n",
      "      ✅ Page 41: Character-based extraction found 98 words\n",
      "      🔍 Page 42 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 42 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 42: Trying character-based extraction...\n",
      "      ✅ Page 42: Character-based extraction found 71 words\n",
      "      🔍 Page 43 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 43 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 43: Trying character-based extraction...\n",
      "      ✅ Page 43: Character-based extraction found 65 words\n",
      "      🔍 Page 44 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 44 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 44: Trying character-based extraction...\n",
      "      ✅ Page 44: Character-based extraction found 192 words\n",
      "      🔍 Page 45 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 45 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 45: Trying character-based extraction...\n",
      "      ✅ Page 45: Character-based extraction found 74 words\n",
      "      🔍 Page 46 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 46 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 46: Trying character-based extraction...\n",
      "      ✅ Page 46: Character-based extraction found 141 words\n",
      "      🔍 Page 47 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 47 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 47: Trying character-based extraction...\n",
      "      ✅ Page 47: Character-based extraction found 105 words\n",
      "      🔍 Page 48 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 48 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 48: Trying character-based extraction...\n",
      "      ✅ Page 48: Character-based extraction found 128 words\n",
      "      🔍 Page 49 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 49 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 49: Trying character-based extraction...\n",
      "      ✅ Page 49: Character-based extraction found 74 words\n",
      "      🔍 Page 50 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 50 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 50: Trying character-based extraction...\n",
      "      ✅ Page 50: Character-based extraction found 141 words\n",
      "    ⚠️  Page 51: Poor pdfplumber extraction (0 chars), trying OCR...\n",
      "      📝 OCR extracted 0 word boxes from page 51\n",
      "      ✅ Page 51: Extracted 0 word boxes\n",
      "      🔍 Page 52 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 52 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 52: Trying character-based extraction...\n",
      "      ✅ Page 52: Character-based extraction found 68 words\n",
      "      🔍 Page 53 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 53 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 53: Trying character-based extraction...\n",
      "      ✅ Page 53: Character-based extraction found 117 words\n",
      "      🔍 Page 54 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 54 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 54: Trying character-based extraction...\n",
      "      ✅ Page 54: Character-based extraction found 165 words\n",
      "      🔍 Page 55 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 55 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 55: Trying character-based extraction...\n",
      "      ✅ Page 55: Character-based extraction found 83 words\n",
      "      🔍 Page 56 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 56 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 56: Trying character-based extraction...\n",
      "      ✅ Page 56: Character-based extraction found 99 words\n",
      "      🔍 Page 57 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 57 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 57: Trying character-based extraction...\n",
      "      ✅ Page 57: Character-based extraction found 39 words\n",
      "      🔍 Page 58 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 58 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 58: Trying character-based extraction...\n",
      "      ✅ Page 58: Character-based extraction found 64 words\n",
      "      🔍 Page 59 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 59 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 59: Trying character-based extraction...\n",
      "      ✅ Page 59: Character-based extraction found 103 words\n",
      "      🔍 Page 60 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 60 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 60: Trying character-based extraction...\n",
      "      ✅ Page 60: Character-based extraction found 41 words\n",
      "    📖 Processed 60 pages...\n",
      "      🔍 Page 61 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 61 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 61: Trying character-based extraction...\n",
      "      ✅ Page 61: Character-based extraction found 126 words\n",
      "      🔍 Page 62 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 62 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 62: Trying character-based extraction...\n",
      "      ✅ Page 62: Character-based extraction found 158 words\n",
      "      🔍 Page 63 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 63 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 63: Trying character-based extraction...\n",
      "      ✅ Page 63: Character-based extraction found 86 words\n",
      "      🔍 Page 64 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 64 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 64: Trying character-based extraction...\n",
      "      ✅ Page 64: Character-based extraction found 126 words\n",
      "      🔍 Page 65 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 65 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 65: Trying character-based extraction...\n",
      "      ✅ Page 65: Character-based extraction found 130 words\n",
      "      🔍 Page 66 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 66 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 66: Trying character-based extraction...\n",
      "      ✅ Page 66: Character-based extraction found 46 words\n",
      "      🔍 Page 67 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 67 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 67: Trying character-based extraction...\n",
      "      ✅ Page 67: Character-based extraction found 142 words\n",
      "      🔍 Page 68 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 68 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 68: Trying character-based extraction...\n",
      "      ✅ Page 68: Character-based extraction found 62 words\n",
      "      🔍 Page 69 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 69 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 69: Trying character-based extraction...\n",
      "      ✅ Page 69: Character-based extraction found 106 words\n",
      "      🔍 Page 70 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 70 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 70: Trying character-based extraction...\n",
      "      ✅ Page 70: Character-based extraction found 84 words\n",
      "      🔍 Page 71 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 71 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 71: Trying character-based extraction...\n",
      "      ✅ Page 71: Character-based extraction found 73 words\n",
      "      🔍 Page 72 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 72 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 72: Trying character-based extraction...\n",
      "      ✅ Page 72: Character-based extraction found 143 words\n",
      "    ⚠️  Page 73: Poor pdfplumber extraction (2 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 73\n",
      "      ✅ Page 73: Extracted 1 word boxes\n",
      "      🔍 Page 74 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 74 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 74: Trying character-based extraction...\n",
      "      ✅ Page 74: Character-based extraction found 204 words\n",
      "      🔍 Page 75 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 75 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 75: Trying character-based extraction...\n",
      "      ✅ Page 75: Character-based extraction found 208 words\n",
      "      🔍 Page 76 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 76 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 76: Trying character-based extraction...\n",
      "      ✅ Page 76: Character-based extraction found 177 words\n",
      "      🔍 Page 77 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 77 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 77: Trying character-based extraction...\n",
      "      ✅ Page 77: Character-based extraction found 37 words\n",
      "      🔍 Page 78 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 78 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 78: Trying character-based extraction...\n",
      "      ✅ Page 78: Character-based extraction found 171 words\n",
      "    ⚠️  Page 79: Poor pdfplumber extraction (71 chars), trying OCR...\n",
      "      📝 OCR extracted 13 word boxes from page 79\n",
      "      ✅ Page 79: Extracted 13 word boxes\n",
      "      🔍 Page 80 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 80 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 80: Trying character-based extraction...\n",
      "      ✅ Page 80: Character-based extraction found 92 words\n",
      "    📖 Processed 80 pages...\n",
      "      🔍 Page 81 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 81 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 81: Trying character-based extraction...\n",
      "      ✅ Page 81: Character-based extraction found 111 words\n",
      "      🔍 Page 82 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 82 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 82: Trying character-based extraction...\n",
      "      ✅ Page 82: Character-based extraction found 114 words\n",
      "    ⚠️  Page 83: Poor pdfplumber extraction (2 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 83\n",
      "      ✅ Page 83: Extracted 1 word boxes\n",
      "      🔍 Page 84 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 84 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 84: Trying character-based extraction...\n",
      "      ✅ Page 84: Character-based extraction found 100 words\n",
      "      🔍 Page 85 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 85 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 85: Trying character-based extraction...\n",
      "      ✅ Page 85: Character-based extraction found 138 words\n",
      "      🔍 Page 86 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 86 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 86: Trying character-based extraction...\n",
      "      ✅ Page 86: Character-based extraction found 141 words\n",
      "      🔍 Page 87 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 87 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 87: Trying character-based extraction...\n",
      "      ✅ Page 87: Character-based extraction found 107 words\n",
      "      🔍 Page 88 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 88 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 88: Trying character-based extraction...\n",
      "      ✅ Page 88: Character-based extraction found 76 words\n",
      "      🔍 Page 89 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 89 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 89: Trying character-based extraction...\n",
      "      ✅ Page 89: Character-based extraction found 106 words\n",
      "    ⚠️  Page 90: Poor pdfplumber extraction (2 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 90\n",
      "      ✅ Page 90: Extracted 1 word boxes\n",
      "      🔍 Page 91 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 91 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 91: Trying character-based extraction...\n",
      "      ✅ Page 91: Character-based extraction found 131 words\n",
      "    ⚠️  Page 92: Poor pdfplumber extraction (2 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 92\n",
      "      ✅ Page 92: Extracted 1 word boxes\n",
      "      🔍 Page 93 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 93 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 93: Trying character-based extraction...\n",
      "      ✅ Page 93: Character-based extraction found 130 words\n",
      "    ⚠️  Page 94: Poor pdfplumber extraction (54 chars), trying OCR...\n",
      "      📝 OCR extracted 9 word boxes from page 94\n",
      "      ✅ Page 94: Extracted 9 word boxes\n",
      "      🔍 Page 95 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 95 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 95: Trying character-based extraction...\n",
      "      ✅ Page 95: Character-based extraction found 136 words\n",
      "      🔍 Page 96 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 96 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 96: Trying character-based extraction...\n",
      "      ✅ Page 96: Character-based extraction found 147 words\n",
      "    ⚠️  Page 97: Poor pdfplumber extraction (2 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 97\n",
      "      ✅ Page 97: Extracted 1 word boxes\n",
      "      🔍 Page 98 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 98 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 98: Trying character-based extraction...\n",
      "      ✅ Page 98: Character-based extraction found 75 words\n",
      "      🔍 Page 99 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 99 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 99: Trying character-based extraction...\n",
      "      ✅ Page 99: Character-based extraction found 148 words\n",
      "      🔍 Page 100 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 100 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 100: Trying character-based extraction...\n",
      "      ✅ Page 100: Character-based extraction found 81 words\n",
      "    📖 Processed 100 pages...\n",
      "      🔍 Page 101 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 101 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 101: Trying character-based extraction...\n",
      "      ✅ Page 101: Character-based extraction found 175 words\n",
      "      🔍 Page 102 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 102 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 102: Trying character-based extraction...\n",
      "      ✅ Page 102: Character-based extraction found 164 words\n",
      "      🔍 Page 103 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 103 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 103: Trying character-based extraction...\n",
      "      ✅ Page 103: Character-based extraction found 94 words\n",
      "      🔍 Page 104 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 104 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 104: Trying character-based extraction...\n",
      "      ✅ Page 104: Character-based extraction found 120 words\n",
      "      🔍 Page 105 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 105 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 105: Trying character-based extraction...\n",
      "      ✅ Page 105: Character-based extraction found 102 words\n",
      "      🔍 Page 106 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 106 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 106: Trying character-based extraction...\n",
      "      ✅ Page 106: Character-based extraction found 155 words\n",
      "      🔍 Page 107 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 107 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 107: Trying character-based extraction...\n",
      "      ✅ Page 107: Character-based extraction found 60 words\n",
      "      🔍 Page 108 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 108 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 108: Trying character-based extraction...\n",
      "      ✅ Page 108: Character-based extraction found 80 words\n",
      "      🔍 Page 109 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 109 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 109: Trying character-based extraction...\n",
      "      ✅ Page 109: Character-based extraction found 102 words\n",
      "      🔍 Page 110 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 110 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 110: Trying character-based extraction...\n",
      "      ✅ Page 110: Character-based extraction found 28 words\n",
      "      🔍 Page 111 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 111 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 111: Trying character-based extraction...\n",
      "      ✅ Page 111: Character-based extraction found 126 words\n",
      "      🔍 Page 112 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 112 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 112: Trying character-based extraction...\n",
      "      ✅ Page 112: Character-based extraction found 34 words\n",
      "      🔍 Page 113 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 113 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 113: Trying character-based extraction...\n",
      "      ✅ Page 113: Character-based extraction found 88 words\n",
      "      🔍 Page 114 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 114 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 114: Trying character-based extraction...\n",
      "      ✅ Page 114: Character-based extraction found 91 words\n",
      "    ⚠️  Page 115: Poor pdfplumber extraction (3 chars), trying OCR...\n",
      "      📝 OCR extracted 1 word boxes from page 115\n",
      "      ✅ Page 115: Extracted 1 word boxes\n",
      "      🔍 Page 116 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 116 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 116: Trying character-based extraction...\n",
      "      ✅ Page 116: Character-based extraction found 86 words\n",
      "    ⚠️  Page 117: Poor pdfplumber extraction (0 chars), trying OCR...\n",
      "      📝 OCR extracted 0 word boxes from page 117\n",
      "      ✅ Page 117: Extracted 0 word boxes\n",
      "      🔍 Page 118 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 118 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 118: Trying character-based extraction...\n",
      "      ✅ Page 118: Character-based extraction found 84 words\n",
      "      🔍 Page 119 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 119 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 119: Trying character-based extraction...\n",
      "      ✅ Page 119: Character-based extraction found 104 words\n",
      "    ⚠️  Page 120: Poor pdfplumber extraction (0 chars), trying OCR...\n",
      "      📝 OCR extracted 0 word boxes from page 120\n",
      "      ✅ Page 120: Extracted 0 word boxes\n",
      "    📖 Processed 120 pages...\n",
      "      🔍 Page 121 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 121 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 121: Trying character-based extraction...\n",
      "      ✅ Page 121: Character-based extraction found 135 words\n",
      "    ⚠️  Page 122: Poor pdfplumber extraction (0 chars), trying OCR...\n",
      "      📝 OCR extracted 0 word boxes from page 122\n",
      "      ✅ Page 122: Extracted 0 word boxes\n",
      "      🔍 Page 123 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 123 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 123: Trying character-based extraction...\n",
      "      ✅ Page 123: Character-based extraction found 94 words\n",
      "    ⚠️  Page 124: Poor pdfplumber extraction (52 chars), trying OCR...\n",
      "      📝 OCR extracted 11 word boxes from page 124\n",
      "      ✅ Page 124: Extracted 11 word boxes\n",
      "      🔍 Page 125 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 125 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 125: Trying character-based extraction...\n",
      "      ✅ Page 125: Character-based extraction found 126 words\n",
      "  ✅ Saved: MSFT_10-K_20240730_000095017024087843_extracted.txt\n",
      "  �� Quality: 109/125 pages via pdfplumber\n",
      "  📦 Saved word boxes: MSFT_10-K_20240730_000095017024087843_wordboxes.json\n",
      "  📐 Saved layout data: MSFT_10-K_20240730_000095017024087843_layout.json\n",
      "  📊 Total word boxes: 12506\n",
      "\n",
      "📄 Processing: MSFT_10-K_20220728_000156459022026876.pdf\n",
      "📅 Year: 2022\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2022/tables/integrated_table_5.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2022/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2022/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2022/tables/integrated_table_7.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2022/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2022/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2022/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2022/tables/integrated_table_8.csv\n",
      "Exported integrated table 9 to ../data/parsed/MSFT/2022/tables/integrated_table_9.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2022/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2022/tables/integrated_table_6.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2022/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2022/tables/integrated_table_6.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2022/tables/integrated_table_5.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 5 to ../data/parsed/MSFT/2022/tables/integrated_table_5.csv\n",
      "Exported integrated table 6 to ../data/parsed/MSFT/2022/tables/integrated_table_6.csv\n",
      "Exported integrated table 7 to ../data/parsed/MSFT/2022/tables/integrated_table_7.csv\n",
      "Exported integrated table 8 to ../data/parsed/MSFT/2022/tables/integrated_table_8.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "Exported integrated table 2 to ../data/parsed/MSFT/2022/tables/integrated_table_2.csv\n",
      "Exported integrated table 3 to ../data/parsed/MSFT/2022/tables/integrated_table_3.csv\n",
      "Exported integrated table 4 to ../data/parsed/MSFT/2022/tables/integrated_table_4.csv\n",
      "Exported integrated table 1 to ../data/parsed/MSFT/2022/tables/integrated_table_1.csv\n",
      "  📄 Total pages: 111\n",
      "      🔍 Page 1 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 1 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 1: Trying character-based extraction...\n",
      "      ✅ Page 1: Character-based extraction found 96 words\n",
      "      🔍 Page 2 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 2 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 2: Trying character-based extraction...\n",
      "      ✅ Page 2: Character-based extraction found 96 words\n",
      "      🔍 Page 3 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 3 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 3: Trying character-based extraction...\n",
      "      ✅ Page 3: Character-based extraction found 77 words\n",
      "      🔍 Page 4 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 4 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 4: Trying character-based extraction...\n",
      "      ✅ Page 4: Character-based extraction found 78 words\n",
      "      🔍 Page 5 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 5 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 5: Trying character-based extraction...\n",
      "      ✅ Page 5: Character-based extraction found 75 words\n",
      "      🔍 Page 6 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 6 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 6: Trying character-based extraction...\n",
      "      ✅ Page 6: Character-based extraction found 55 words\n",
      "      🔍 Page 7 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 7 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 7: Trying character-based extraction...\n",
      "      ✅ Page 7: Character-based extraction found 84 words\n",
      "      🔍 Page 8 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 8 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 8: Trying character-based extraction...\n",
      "      ✅ Page 8: Character-based extraction found 83 words\n",
      "      🔍 Page 9 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 9 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 9: Trying character-based extraction...\n",
      "      ✅ Page 9: Character-based extraction found 99 words\n",
      "      🔍 Page 10 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 10 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 10: Trying character-based extraction...\n",
      "      ✅ Page 10: Character-based extraction found 65 words\n",
      "      🔍 Page 11 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 11 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 11: Trying character-based extraction...\n",
      "      ✅ Page 11: Character-based extraction found 55 words\n",
      "      🔍 Page 12 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 12 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 12: Trying character-based extraction...\n",
      "      ✅ Page 12: Character-based extraction found 82 words\n",
      "      🔍 Page 13 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 13 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 13: Trying character-based extraction...\n",
      "      ✅ Page 13: Character-based extraction found 81 words\n",
      "      🔍 Page 14 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 14 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 14: Trying character-based extraction...\n",
      "      ✅ Page 14: Character-based extraction found 71 words\n",
      "      🔍 Page 15 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 15 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 15: Trying character-based extraction...\n",
      "      ✅ Page 15: Character-based extraction found 45 words\n",
      "      🔍 Page 16 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 16 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 16: Trying character-based extraction...\n",
      "      ✅ Page 16: Character-based extraction found 55 words\n",
      "      🔍 Page 17 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 17 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 17: Trying character-based extraction...\n",
      "      ✅ Page 17: Character-based extraction found 75 words\n",
      "      🔍 Page 18 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 18 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 18: Trying character-based extraction...\n",
      "      ✅ Page 18: Character-based extraction found 57 words\n",
      "      🔍 Page 19 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 19 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 19: Trying character-based extraction...\n",
      "      ✅ Page 19: Character-based extraction found 115 words\n",
      "      🔍 Page 20 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 20 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 20: Trying character-based extraction...\n",
      "      ✅ Page 20: Character-based extraction found 7 words\n",
      "    📖 Processed 20 pages...\n",
      "      🔍 Page 21 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 21 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 21: Trying character-based extraction...\n",
      "      ✅ Page 21: Character-based extraction found 111 words\n",
      "      🔍 Page 22 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 22 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 22: Trying character-based extraction...\n",
      "      ✅ Page 22: Character-based extraction found 42 words\n",
      "      🔍 Page 23 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 23 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 23: Trying character-based extraction...\n",
      "      ✅ Page 23: Character-based extraction found 77 words\n",
      "      🔍 Page 24 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 24 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 24: Trying character-based extraction...\n",
      "      ✅ Page 24: Character-based extraction found 55 words\n",
      "      🔍 Page 25 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 25 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 25: Trying character-based extraction...\n",
      "      ✅ Page 25: Character-based extraction found 94 words\n",
      "      🔍 Page 26 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 26 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 26: Trying character-based extraction...\n",
      "      ✅ Page 26: Character-based extraction found 37 words\n",
      "      🔍 Page 27 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 27 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 27: Trying character-based extraction...\n",
      "      ✅ Page 27: Character-based extraction found 60 words\n",
      "      🔍 Page 28 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 28 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 28: Trying character-based extraction...\n",
      "      ✅ Page 28: Character-based extraction found 101 words\n",
      "      🔍 Page 29 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 29 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 29: Trying character-based extraction...\n",
      "      ✅ Page 29: Character-based extraction found 83 words\n",
      "      🔍 Page 30 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 30 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 30: Trying character-based extraction...\n",
      "      ✅ Page 30: Character-based extraction found 61 words\n",
      "      🔍 Page 31 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 31 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 31: Trying character-based extraction...\n",
      "      ✅ Page 31: Character-based extraction found 62 words\n",
      "      🔍 Page 32 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 32 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 32: Trying character-based extraction...\n",
      "      ✅ Page 32: Character-based extraction found 79 words\n",
      "      🔍 Page 33 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 33 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 33: Trying character-based extraction...\n",
      "      ✅ Page 33: Character-based extraction found 145 words\n",
      "      🔍 Page 34 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 34 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 34: Trying character-based extraction...\n",
      "      ✅ Page 34: Character-based extraction found 67 words\n",
      "      🔍 Page 35 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 35 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 35: Trying character-based extraction...\n",
      "      ✅ Page 35: Character-based extraction found 62 words\n",
      "      🔍 Page 36 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 36 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 36: Trying character-based extraction...\n",
      "      ✅ Page 36: Character-based extraction found 81 words\n",
      "      🔍 Page 37 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 37 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 37: Trying character-based extraction...\n",
      "      ✅ Page 37: Character-based extraction found 58 words\n",
      "      🔍 Page 38 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 38 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 38: Trying character-based extraction...\n",
      "      ✅ Page 38: Character-based extraction found 68 words\n",
      "    ⚠️  Page 39: Poor pdfplumber extraction (36 chars), trying OCR...\n",
      "      📝 OCR extracted 8 word boxes from page 39\n",
      "      ✅ Page 39: Extracted 8 word boxes\n",
      "      🔍 Page 40 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 40 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 40: Trying character-based extraction...\n",
      "      ✅ Page 40: Character-based extraction found 57 words\n",
      "    📖 Processed 40 pages...\n",
      "      🔍 Page 41 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 41 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 41: Trying character-based extraction...\n",
      "      ✅ Page 41: Character-based extraction found 96 words\n",
      "      🔍 Page 42 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 42 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 42: Trying character-based extraction...\n",
      "      ✅ Page 42: Character-based extraction found 109 words\n",
      "      🔍 Page 43 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 43 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 43: Trying character-based extraction...\n",
      "      ✅ Page 43: Character-based extraction found 120 words\n",
      "      🔍 Page 44 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 44 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 44: Trying character-based extraction...\n",
      "      ✅ Page 44: Character-based extraction found 85 words\n",
      "      🔍 Page 45 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 45 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 45: Trying character-based extraction...\n",
      "      ✅ Page 45: Character-based extraction found 54 words\n",
      "      🔍 Page 46 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 46 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 46: Trying character-based extraction...\n",
      "      ✅ Page 46: Character-based extraction found 105 words\n",
      "      🔍 Page 47 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 47 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 47: Trying character-based extraction...\n",
      "      ✅ Page 47: Character-based extraction found 81 words\n",
      "      🔍 Page 48 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 48 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 48: Trying character-based extraction...\n",
      "      ✅ Page 48: Character-based extraction found 89 words\n",
      "      🔍 Page 49 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 49 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 49: Trying character-based extraction...\n",
      "      ✅ Page 49: Character-based extraction found 74 words\n",
      "      🔍 Page 50 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 50 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 50: Trying character-based extraction...\n",
      "      ✅ Page 50: Character-based extraction found 36 words\n",
      "      🔍 Page 51 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 51 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 51: Trying character-based extraction...\n",
      "      ✅ Page 51: Character-based extraction found 74 words\n",
      "      🔍 Page 52 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 52 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 52: Trying character-based extraction...\n",
      "      ✅ Page 52: Character-based extraction found 57 words\n",
      "      🔍 Page 53 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 53 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 53: Trying character-based extraction...\n",
      "      ✅ Page 53: Character-based extraction found 45 words\n",
      "      🔍 Page 54 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 54 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 54: Trying character-based extraction...\n",
      "      ✅ Page 54: Character-based extraction found 54 words\n",
      "      🔍 Page 55 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 55 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 55: Trying character-based extraction...\n",
      "      ✅ Page 55: Character-based extraction found 25 words\n",
      "      🔍 Page 56 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 56 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 56: Trying character-based extraction...\n",
      "      ✅ Page 56: Character-based extraction found 53 words\n",
      "      🔍 Page 57 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 57 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 57: Trying character-based extraction...\n",
      "      ✅ Page 57: Character-based extraction found 103 words\n",
      "      🔍 Page 58 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 58 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 58: Trying character-based extraction...\n",
      "      ✅ Page 58: Character-based extraction found 41 words\n",
      "      🔍 Page 59 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 59 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 59: Trying character-based extraction...\n",
      "      ✅ Page 59: Character-based extraction found 122 words\n",
      "      🔍 Page 60 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 60 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 60: Trying character-based extraction...\n",
      "      ✅ Page 60: Character-based extraction found 154 words\n",
      "    📖 Processed 60 pages...\n",
      "      🔍 Page 61 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 61 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 61: Trying character-based extraction...\n",
      "      ✅ Page 61: Character-based extraction found 94 words\n",
      "      🔍 Page 62 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 62 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 62: Trying character-based extraction...\n",
      "      ✅ Page 62: Character-based extraction found 85 words\n",
      "      🔍 Page 63 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 63 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 63: Trying character-based extraction...\n",
      "      ✅ Page 63: Character-based extraction found 75 words\n",
      "      🔍 Page 64 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 64 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 64: Trying character-based extraction...\n",
      "      ✅ Page 64: Character-based extraction found 71 words\n",
      "      🔍 Page 65 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 65 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 65: Trying character-based extraction...\n",
      "      ✅ Page 65: Character-based extraction found 83 words\n",
      "      🔍 Page 66 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 66 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 66: Trying character-based extraction...\n",
      "      ✅ Page 66: Character-based extraction found 64 words\n",
      "      🔍 Page 67 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 67 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 67: Trying character-based extraction...\n",
      "      ✅ Page 67: Character-based extraction found 94 words\n",
      "      🔍 Page 68 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 68 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 68: Trying character-based extraction...\n",
      "      ✅ Page 68: Character-based extraction found 61 words\n",
      "      🔍 Page 69 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 69 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 69: Trying character-based extraction...\n",
      "      ✅ Page 69: Character-based extraction found 103 words\n",
      "      🔍 Page 70 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 70 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 70: Trying character-based extraction...\n",
      "      ✅ Page 70: Character-based extraction found 60 words\n",
      "      🔍 Page 71 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 71 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 71: Trying character-based extraction...\n",
      "      ✅ Page 71: Character-based extraction found 191 words\n",
      "      🔍 Page 72 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 72 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 72: Trying character-based extraction...\n",
      "      ✅ Page 72: Character-based extraction found 264 words\n",
      "      🔍 Page 73 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 73 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 73: Trying character-based extraction...\n",
      "      ✅ Page 73: Character-based extraction found 58 words\n",
      "      🔍 Page 74 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 74 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 74: Trying character-based extraction...\n",
      "      ✅ Page 74: Character-based extraction found 123 words\n",
      "      🔍 Page 75 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 75 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 75: Trying character-based extraction...\n",
      "      ✅ Page 75: Character-based extraction found 52 words\n",
      "      🔍 Page 76 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 76 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 76: Trying character-based extraction...\n",
      "      ✅ Page 76: Character-based extraction found 142 words\n",
      "      🔍 Page 77 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 77 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 77: Trying character-based extraction...\n",
      "      ✅ Page 77: Character-based extraction found 89 words\n",
      "      🔍 Page 78 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 78 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 78: Trying character-based extraction...\n",
      "      ✅ Page 78: Character-based extraction found 71 words\n",
      "      🔍 Page 79 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 79 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 79: Trying character-based extraction...\n",
      "      ✅ Page 79: Character-based extraction found 72 words\n",
      "      🔍 Page 80 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 80 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 80: Trying character-based extraction...\n",
      "      ✅ Page 80: Character-based extraction found 160 words\n",
      "    📖 Processed 80 pages...\n",
      "      🔍 Page 81 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 81 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 81: Trying character-based extraction...\n",
      "      ✅ Page 81: Character-based extraction found 63 words\n",
      "      🔍 Page 82 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 82 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 82: Trying character-based extraction...\n",
      "      ✅ Page 82: Character-based extraction found 149 words\n",
      "      🔍 Page 83 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 83 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 83: Trying character-based extraction...\n",
      "      ✅ Page 83: Character-based extraction found 139 words\n",
      "      🔍 Page 84 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 84 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 84: Trying character-based extraction...\n",
      "      ✅ Page 84: Character-based extraction found 31 words\n",
      "      🔍 Page 85 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 85 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 85: Trying character-based extraction...\n",
      "      ✅ Page 85: Character-based extraction found 103 words\n",
      "      🔍 Page 86 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 86 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 86: Trying character-based extraction...\n",
      "      ✅ Page 86: Character-based extraction found 96 words\n",
      "      🔍 Page 87 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 87 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 87: Trying character-based extraction...\n",
      "      ✅ Page 87: Character-based extraction found 88 words\n",
      "      🔍 Page 88 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 88 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 88: Trying character-based extraction...\n",
      "      ✅ Page 88: Character-based extraction found 109 words\n",
      "      🔍 Page 89 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 89 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 89: Trying character-based extraction...\n",
      "      ✅ Page 89: Character-based extraction found 54 words\n",
      "      🔍 Page 90 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 90 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 90: Trying character-based extraction...\n",
      "      ✅ Page 90: Character-based extraction found 98 words\n",
      "      🔍 Page 91 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 91 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 91: Trying character-based extraction...\n",
      "      ✅ Page 91: Character-based extraction found 69 words\n",
      "      🔍 Page 92 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 92 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 92: Trying character-based extraction...\n",
      "      ✅ Page 92: Character-based extraction found 134 words\n",
      "      🔍 Page 93 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 93 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 93: Trying character-based extraction...\n",
      "      ✅ Page 93: Character-based extraction found 101 words\n",
      "      🔍 Page 94 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 94 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 94: Trying character-based extraction...\n",
      "      ✅ Page 94: Character-based extraction found 83 words\n",
      "      🔍 Page 95 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 95 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 95: Trying character-based extraction...\n",
      "      ✅ Page 95: Character-based extraction found 96 words\n",
      "      🔍 Page 96 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 96 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 96: Trying character-based extraction...\n",
      "      ✅ Page 96: Character-based extraction found 93 words\n",
      "      🔍 Page 97 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 97 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 97: Trying character-based extraction...\n",
      "      ✅ Page 97: Character-based extraction found 53 words\n",
      "      🔍 Page 98 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 98 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 98: Trying character-based extraction...\n",
      "      ✅ Page 98: Character-based extraction found 62 words\n",
      "      🔍 Page 99 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 99 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 99: Trying character-based extraction...\n",
      "      ✅ Page 99: Character-based extraction found 109 words\n",
      "      🔍 Page 100 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 100 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 100: Trying character-based extraction...\n",
      "      ✅ Page 100: Character-based extraction found 44 words\n",
      "    📖 Processed 100 pages...\n",
      "      🔍 Page 101 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 101 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 101: Trying character-based extraction...\n",
      "      ✅ Page 101: Character-based extraction found 93 words\n",
      "      🔍 Page 102 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 102 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 102: Trying character-based extraction...\n",
      "      ✅ Page 102: Character-based extraction found 76 words\n",
      "      🔍 Page 103 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 103 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 103: Trying character-based extraction...\n",
      "      ✅ Page 103: Character-based extraction found 82 words\n",
      "      🔍 Page 104 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 104 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 104: Trying character-based extraction...\n",
      "      ✅ Page 104: Character-based extraction found 78 words\n",
      "      🔍 Page 105 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 105 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 105: Trying character-based extraction...\n",
      "      ✅ Page 105: Character-based extraction found 71 words\n",
      "      🔍 Page 106 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 106 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 106: Trying character-based extraction...\n",
      "      ✅ Page 106: Character-based extraction found 109 words\n",
      "      🔍 Page 107 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 107 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 107: Trying character-based extraction...\n",
      "      ✅ Page 107: Character-based extraction found 116 words\n",
      "      🔍 Page 108 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 108 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 108: Trying character-based extraction...\n",
      "      ✅ Page 108: Character-based extraction found 52 words\n",
      "    ⚠️  Page 109: Poor pdfplumber extraction (52 chars), trying OCR...\n",
      "      📝 OCR extracted 11 word boxes from page 109\n",
      "      ✅ Page 109: Extracted 11 word boxes\n",
      "      🔍 Page 110 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 110 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 110: Trying character-based extraction...\n",
      "      ✅ Page 110: Character-based extraction found 16 words\n",
      "      🔍 Page 111 - Available word attributes: ['text', 'x0', 'x1', 'top', 'doctop', 'bottom', 'upright', 'height', 'width', 'direction']\n",
      "      ⚠️  Page 111 - Missing required attributes: ['y0', 'y1']\n",
      "      🔄 Page 111: Trying character-based extraction...\n",
      "      ✅ Page 111: Character-based extraction found 92 words\n",
      "  ✅ Saved: MSFT_10-K_20220728_000156459022026876_extracted.txt\n",
      "  �� Quality: 109/111 pages via pdfplumber\n",
      "  📦 Saved word boxes: MSFT_10-K_20220728_000156459022026876_wordboxes.json\n",
      "  📐 Saved layout data: MSFT_10-K_20220728_000156459022026876_layout.json\n",
      "  📊 Total word boxes: 9018\n",
      "\n",
      "================================================================================\n",
      "📊 PDF PROCESSING SUMMARY\n",
      "================================================================================\n",
      "📁 Files Processed:\n",
      "  Total files: 3\n",
      "  Successfully processed: 3\n",
      "  Failed: 0\n",
      "  Success rate: 100.0%\n",
      "\n",
      "📄 Page Statistics:\n",
      "  Total pages processed: 353\n",
      "  PDFplumber extractions: 328\n",
      "  OCR extractions: 25\n",
      "  Poor quality pages: 25\n",
      "\n",
      "📦 Word Box Statistics:\n",
      "  Total word boxes extracted: 40423\n",
      "  Average word boxes per page: 114.5\n",
      "\n",
      "�� Quality Metrics:\n",
      "  PDFplumber success rate: 92.9%\n",
      "  OCR fallback rate: 7.1%\n",
      "  Poor quality rate: 7.1%\n",
      "\n",
      "⚡ Performance:\n",
      "  Average pages per file: 117.7\n",
      "  Average word boxes per file: 13474.3\n",
      "\n",
      "💡 Recommendations:\n",
      "  ✅ Good extraction quality - most pages processed with PDFplumber\n",
      "\n",
      "================================================================================\n",
      "🎉 Processing completed successfully!\n",
      "📦 Word boxes and layout data saved for LayoutLMv3 analysis\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "process_all_pdfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41fa37",
   "metadata": {},
   "source": [
    "Use the below cells to refresh the script run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d001078e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ MSFT folder not found in parsed directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Path to the MSFT folder within parsed directory\n",
    "msft_path = \"../data/parsed/MSFT\"\n",
    "tables_path = \"../data/tables\"\n",
    "tabula_path = \"../data/parsed/tabula_output/\"\n",
    "# Check if directory exists before attempting removal\n",
    "if os.path.exists(msft_path):\n",
    "    print(f\"Removing {msft_path}...\")\n",
    "    try:\n",
    "        shutil.rmtree(msft_path)\n",
    "        shutil.rmtree(tabula_path)\n",
    "        shutil.rmtree(tables_path)\n",
    "        print(\"✅ MSFT folder successfully removed\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error removing MSFT folder: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ MSFT folder not found in parsed directory\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
