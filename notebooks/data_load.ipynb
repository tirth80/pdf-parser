{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3b4eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from sec_api import QueryApi, PdfGeneratorApi, XbrlApi\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c26159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "# You need to get your API key from https://sec-api.io/\n",
    "# For demonstration, we'll use a placeholder - replace with your actual API key\n",
    "SEC_API_KEY = os.getenv(\"SEC_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6468a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the APIs\n",
    "query_api = QueryApi(api_key=SEC_API_KEY)\n",
    "pdf_generator = PdfGeneratorApi(api_key=SEC_API_KEY)\n",
    "xbrl_api = XbrlApi(SEC_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c11a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the data/raw directory if it doesn't exist\n",
    "raw_data_dir = \"../data/raw/MSFT/10-K/PDFs\"\n",
    "xbrl_data_dir=\"../data/raw/MSFT/10-K/XBRL\"\n",
    "os.makedirs(raw_data_dir, exist_ok=True)\n",
    "os.makedirs(xbrl_data_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741d8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Microsoft's ticker symbol and CIK (Central Index Key)\n",
    "ticker = \"MSFT\"\n",
    "cik = \"0000789019\"  # Microsoft's CIK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9158fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Searching for MSFT 10-K filings from the last 2 years...\n",
      " PDFs will be saved to: /Users/smatcha/Documents/BigData/pdf-parser/data/raw/MSFT/10-K/PDFs\n",
      "XBRL data will be saved to:/Users/smatcha/Documents/BigData/pdf-parser/data/raw/MSFT/10-K/XBRL \n",
      "üîç Querying SEC database...\n",
      "üìã Found 3 10-K filings for MSFT\n",
      "\n",
      "üìÑ Available filings:\n",
      "  1. Filed: 2024-07-30 | Accession: 0000950170-24-087843\n",
      "  2. Filed: 2023-07-27 | Accession: 0000950170-23-035122\n",
      "  3. Filed: 2022-07-28 | Accession: 0001564590-22-026876\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\" Searching for {ticker} 10-K filings from the last 2 years...\")\n",
    "print(f\" PDFs will be saved to: {os.path.abspath(raw_data_dir)}\")\n",
    "print(f\"XBRL data will be saved to:{os.path.abspath(xbrl_data_dir)} \")\n",
    "if SEC_API_KEY:\n",
    "    try:\n",
    "        # Query for Microsoft 10-K filings from the last 2 years\n",
    "        query = {\n",
    "            \"query\": f\"ticker:{ticker} AND formType:\\\"10-K\\\" AND filedAt:[2022-01-01 TO 2024-12-31]\",\n",
    "            \"from\": \"0\",\n",
    "            \"size\": \"10\",\n",
    "            \"sort\": [{\"filedAt\": {\"order\": \"desc\"}}]\n",
    "        }\n",
    "        \n",
    "        print(\"üîç Querying SEC database...\")\n",
    "        response = query_api.get_filings(query)\n",
    "        \n",
    "        filings = response[\"filings\"]\n",
    "        print(f\"üìã Found {len(filings)} 10-K filings for {ticker}\")\n",
    "        \n",
    "        if len(filings) == 0:\n",
    "            print(\"‚ùå No filings found. Try adjusting the date range or check the ticker symbol.\")\n",
    "        else:\n",
    "            print(\"\\nüìÑ Available filings:\")\n",
    "            for i, filing in enumerate(filings):\n",
    "                filed_date = filing[\"filedAt\"][:10]  # Extract date part\n",
    "                accession_no = filing[\"accessionNo\"]\n",
    "                print(f\"  {i+1}. Filed: {filed_date} | Accession: {accession_no}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error querying filings: {e}\")\n",
    "        print(\"Make sure your API key is valid and you have internet connection.\")\n",
    "        filings = []\n",
    "else:\n",
    "    print(\"‚è© Skipping API calls - please configure your API key first\")\n",
    "    filings = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fcdc263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting SEC filings to PDF format...\n",
      "üìÇ Saving PDFs to: ../data/raw/MSFT/10-K/PDFs\n",
      "  ‚è© Skipping MSFT_10-K_20240730_000095017024087843.pdf (already exists)\n",
      "  ‚è© Skipping MSFT_10-K_20230727_000095017023035122.pdf (already exists)\n",
      "  ‚è© Skipping MSFT_10-K_20220728_000156459022026876.pdf (already exists)\n",
      "\n",
      "üìä Download Summary:\n",
      "  Total filings found: 3\n",
      "  PDFs successfully downloaded: 3\n",
      "  Success rate: 100.0%\n",
      "\n",
      "üìã PDF files ready for parsing in ../data/raw/MSFT/10-K/PDFs:\n",
      "  üìÑ MSFT_10-K_20220728_000156459022026876.pdf (11.7 MB)\n",
      "  üìÑ MSFT_10-K_20230727_000095017023035122.pdf (11.9 MB)\n",
      "  üìÑ MSFT_10-K_20240730_000095017024087843.pdf (12.2 MB)\n",
      "\n",
      "üíæ Total size: 35.8 MB\n",
      "üéØ Ready for PDF parsing with your PDF parser!\n"
     ]
    }
   ],
   "source": [
    "# Generate PDFs from the found filings using sec-api PdfGeneratorApi\n",
    "if SEC_API_KEY and 'filings' in locals() and len(filings) > 0:\n",
    "    print(\"üîÑ Converting SEC filings to PDF format...\")\n",
    "    print(f\"üìÇ Saving PDFs to: {raw_data_dir}\")\n",
    "    \n",
    "    successfully_downloaded = 0\n",
    "    \n",
    "    for i, filing in enumerate(filings):\n",
    "        try:\n",
    "            # Extract filing information\n",
    "            filed_date = filing[\"filedAt\"][:10].replace(\"-\", \"\")  # Format: YYYYMMDD\n",
    "            accession_no = filing[\"accessionNo\"].replace(\"-\", \"\")\n",
    "            form_type = filing[\"formType\"]\n",
    "            \n",
    "            # Create filename\n",
    "            pdf_filename = f\"{ticker}_{form_type}_{filed_date}_{accession_no}.pdf\"\n",
    "            pdf_path = os.path.join(raw_data_dir, pdf_filename)\n",
    "            \n",
    "            # Skip if file already exists\n",
    "            if os.path.exists(pdf_path):\n",
    "                print(f\"  ‚è© Skipping {pdf_filename} (already exists)\")\n",
    "                successfully_downloaded += 1\n",
    "                continue\n",
    "            \n",
    "            print(f\"  üîÑ Processing filing {i+1}/{len(filings)}: {filed_date}\")\n",
    "            \n",
    "            # Get the filing URL\n",
    "            filing_url = filing[\"linkToFilingDetails\"]\n",
    "            \n",
    "            # Generate PDF using sec-api\n",
    "            print(f\"    üìÑ Generating PDF from: {filing_url}\")\n",
    "            \n",
    "            # Add a small delay to respect rate limits\n",
    "            if i > 0:\n",
    "                time.sleep(1)  # 1 second delay between requests\n",
    "            \n",
    "            pdf_content = pdf_generator.get_pdf(filing_url)\n",
    "            \n",
    "            # Save PDF to file\n",
    "            with open(pdf_path, 'wb') as pdf_file:\n",
    "                pdf_file.write(pdf_content)\n",
    "            \n",
    "            # Check file size\n",
    "            file_size = os.path.getsize(pdf_path) / (1024 * 1024)  # Size in MB\n",
    "            \n",
    "            if file_size > 0.1:  # At least 100KB\n",
    "                print(f\"    ‚úÖ Successfully saved: {pdf_filename} ({file_size:.1f} MB)\")\n",
    "                successfully_downloaded += 1\n",
    "            else:\n",
    "                print(f\"    ‚ö†Ô∏è  Warning: Small file size for {pdf_filename} ({file_size:.1f} MB)\")\n",
    "                successfully_downloaded += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ùå Error processing filing {i+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nüìä Download Summary:\")\n",
    "    print(f\"  Total filings found: {len(filings)}\")\n",
    "    print(f\"  PDFs successfully downloaded: {successfully_downloaded}\")\n",
    "    print(f\"  Success rate: {(successfully_downloaded/len(filings)*100):.1f}%\")\n",
    "    \n",
    "    # List final PDF files\n",
    "    if os.path.exists(raw_data_dir):\n",
    "        pdf_files = [f for f in os.listdir(raw_data_dir) if f.lower().endswith('.pdf')]\n",
    "        \n",
    "        if pdf_files:\n",
    "            print(f\"\\nüìã PDF files ready for parsing in {raw_data_dir}:\")\n",
    "            total_size = 0\n",
    "            for pdf_file in sorted(pdf_files):\n",
    "                file_path = os.path.join(raw_data_dir, pdf_file)\n",
    "                file_size = os.path.getsize(file_path) / (1024 * 1024)\n",
    "                total_size += file_size\n",
    "                print(f\"  üìÑ {pdf_file} ({file_size:.1f} MB)\")\n",
    "            \n",
    "            print(f\"\\nüíæ Total size: {total_size:.1f} MB\")\n",
    "            print(f\"üéØ Ready for PDF parsing with your PDF parser!\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå No PDF files were created. Check the error messages above.\")\n",
    "\n",
    "elif SEC_API_KEY == \"YOUR_API_KEY_HERE\":\n",
    "    print(\"‚ö†Ô∏è  Please configure your SEC API key first before generating PDFs\")\n",
    "    print(\"üìã Steps:\")\n",
    "    print(\"  1. Sign up at https://sec-api.io/\")\n",
    "    print(\"  2. Get your API key from the dashboard\")\n",
    "    print(\"  3. Replace 'YOUR_API_KEY_HERE' in the first cell\")\n",
    "    print(\"  4. Re-run both cells\")\n",
    "    \n",
    "elif 'filings' not in locals() or len(filings) == 0:\n",
    "    print(\"‚ùå No filings available for PDF generation\")\n",
    "    print(\"Please run the first cell successfully to fetch filings first\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Unexpected state - please re-run the first cell\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e89af26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using User-Agent: Riyanshi Kedia riyanshi@example.com - academic XBRL research\n",
      "\n",
      "üì¶ Downloading XBRL artifacts from filings...\n",
      "üìÇ Output root: ../data/raw/MSFT/10-K/XBRL\n",
      "  üì• [1/3] 10-K 20240730 ‚Üí ../data/raw/MSFT/10-K/XBRL/MSFT_10-K_20240730_xbrl\n",
      "    ‚úÖ Saved 15 file(s) via zip\n",
      "  üì• [2/3] 10-K 20230727 ‚Üí ../data/raw/MSFT/10-K/XBRL/MSFT_10-K_20230727_xbrl\n",
      "    ‚úÖ Saved 13 file(s) via zip\n",
      "  üì• [3/3] 10-K 20220728 ‚Üí ../data/raw/MSFT/10-K/XBRL/MSFT_10-K_20220728_xbrl\n",
      "    ‚úÖ Saved 13 file(s) via zip\n",
      "\n",
      "üìä XBRL Download Summary\n",
      "  Total filings: 3\n",
      "  With XBRL saved: 3\n",
      "  Success rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# === XBRL Downloader ‚Äî one cell drop-in ===\n",
    "\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import zipfile\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import requests\n",
    "\n",
    "# Optional (only if you also want JSON/CSV)\n",
    "try:\n",
    "    from sec_api import XbrlApi\n",
    "except Exception:\n",
    "    XbrlApi = None  # sec-api not installed/available; raw XBRL download will still work\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Configuration (safe defaults)\n",
    "# ==============================\n",
    "# You can override these earlier in your notebook.\n",
    "ticker = globals().get(\"ticker\", \"MSFT\")\n",
    "cik = globals().get(\"cik\", \"0000789019\")  # Microsoft (with leading zeros)\n",
    "xbrl_data_dir = globals().get(\"xbrl_data_dir\", f\"./data/xbrl/{ticker}\")\n",
    "\n",
    "# If you also want JSON/CSV from sec-api, set to True and provide your SEC_API_KEY\n",
    "PRODUCE_JSON_AND_CSV = False\n",
    "SEC_API_KEY = os.environ.get(\"SEC_API_KEY\", globals().get(\"SEC_API_KEY\"))\n",
    "xbrl_api = XbrlApi(SEC_API_KEY) if (PRODUCE_JSON_AND_CSV and XbrlApi and SEC_API_KEY) else None\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# User-Agent (ASCII-only to avoid latin-1 errors)\n",
    "# ==============================\n",
    "def ascii_http_header(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert Unicode to safe ASCII for HTTP headers:\n",
    "    - Replace en/em dashes with '-'\n",
    "    - NFKD normalize\n",
    "    - Replace non-latin-1 chars with '-'\n",
    "    \"\"\"\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = s.replace(\"\\u2013\", \"-\").replace(\"\\u2014\", \"-\")\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    return \"\".join(ch if ord(ch) < 256 else \"-\" for ch in s)\n",
    "\n",
    "UA_RAW = os.environ.get(\n",
    "    \"SEC_USER_AGENT\",\n",
    "    # Put your name/email/purpose here to comply with SEC fair access guidance\n",
    "    \"Riyanshi Kedia riyanshi@example.com - academic XBRL research\"\n",
    ")\n",
    "USER_AGENT = ascii_http_header(UA_RAW).strip() or \"pdf-parser - contact@example.com\"\n",
    "REQUEST_KW = {\"headers\": {\"User-Agent\": USER_AGENT}, \"timeout\": 30}\n",
    "\n",
    "print(\"Using User-Agent:\", USER_AGENT)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Helper functions\n",
    "# ==============================\n",
    "def _clean_cik(cik_str: str) -> str:\n",
    "    \"\"\"Strip leading zeros from CIK for EDGAR paths.\"\"\"\n",
    "    return str(int(str(cik_str).strip()))\n",
    "\n",
    "def _clean_accession(acc: str) -> str:\n",
    "    \"\"\"Remove hyphens from accession number for path segments.\"\"\"\n",
    "    return str(acc).replace(\"-\", \"\").strip()\n",
    "\n",
    "def submission_base_url(cik_str: str, accession_no: str) -> str:\n",
    "    \"\"\"e.g. https://www.sec.gov/Archives/edgar/data/789019/000156459022026876\"\"\"\n",
    "    return f\"https://www.sec.gov/Archives/edgar/data/{_clean_cik(cik_str)}/{_clean_accession(accession_no)}\"\n",
    "\n",
    "def xbrl_zip_url(cik_str: str, accession_no: str) -> str:\n",
    "    \"\"\"e.g. .../000156459022026876/0001564590-22-026876-xbrl.zip (note: hyphens kept in file name)\"\"\"\n",
    "    return f\"{submission_base_url(cik_str, accession_no)}/{accession_no}-xbrl.zip\"\n",
    "\n",
    "def index_json_url(cik_str: str, accession_no: str) -> str:\n",
    "    \"\"\"EDGAR directory index JSON.\"\"\"\n",
    "    return f\"{submission_base_url(cik_str, accession_no)}/index.json\"\n",
    "\n",
    "\n",
    "# Common XBRL file patterns (instance + linkbases + schema + (i)XBRL HTML)\n",
    "XBRL_FILE_PATTERNS = [\n",
    "    r\".*?-ins\\.xml$\",    # instance\n",
    "    r\".*?-pre\\.xml$\",    # presentation\n",
    "    r\".*?-cal\\.xml$\",    # calculation\n",
    "    r\".*?-def\\.xml$\",    # definition\n",
    "    r\".*?-lab\\.xml$\",    # labels\n",
    "    r\".*?\\.xsd$\",        # schema\n",
    "    r\".*?\\.(?:htm|html)$\",  # (inline) XBRL HTML\n",
    "]\n",
    "_XBRL_REGEXES = [re.compile(p, re.IGNORECASE) for p in XBRL_FILE_PATTERNS]\n",
    "\n",
    "def looks_like_xbrl(filename: str) -> bool:\n",
    "    return any(rx.search(filename) for rx in _XBRL_REGEXES)\n",
    "\n",
    "\n",
    "def download_xbrl_zip_or_files(cik_str: str, accession_no: str, dest_dir: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Try downloading -xbrl.zip. If not present, fall back to per-file download via index.json.\n",
    "    Returns: {\"mode\": \"zip\" | \"files\", \"saved\": [list_of_paths]}\n",
    "    \"\"\"\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    saved: List[str] = []\n",
    "\n",
    "    # 1) Try ZIP first\n",
    "    zip_url = xbrl_zip_url(cik_str, accession_no)\n",
    "    try:\n",
    "        r = requests.get(zip_url, **REQUEST_KW)\n",
    "        if r.status_code == 200 and r.content:\n",
    "            zip_path = os.path.join(dest_dir, f\"{_clean_accession(accession_no)}-xbrl.zip\")\n",
    "            with open(zip_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "            # Extract contents for convenience\n",
    "            with zipfile.ZipFile(io.BytesIO(r.content)) as zf:\n",
    "                zf.extractall(dest_dir)\n",
    "                saved.extend([str(Path(dest_dir, name)) for name in zf.namelist()])\n",
    "            saved.append(zip_path)\n",
    "            return {\"mode\": \"zip\", \"saved\": saved}\n",
    "        # else: fall through to index.json mode\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ÑπÔ∏è ZIP attempt failed: {e}\")\n",
    "\n",
    "    # 2) Fallback: enumerate directory and download files individually\n",
    "    idx_url = index_json_url(cik_str, accession_no)\n",
    "    r = requests.get(idx_url, **REQUEST_KW)\n",
    "    if r.status_code != 200:\n",
    "        raise RuntimeError(f\"index.json not accessible (status {r.status_code}) at {idx_url}\")\n",
    "\n",
    "    data = r.json()\n",
    "    items = (data.get(\"directory\") or {}).get(\"item\") or []\n",
    "    if not items:\n",
    "        raise RuntimeError(\"No items found in submission index.json\")\n",
    "\n",
    "    base = submission_base_url(cik_str, accession_no)\n",
    "    for it in items:\n",
    "        name = it.get(\"name\")\n",
    "        if not name:\n",
    "            continue\n",
    "        if looks_like_xbrl(name):\n",
    "            file_url = f\"{base}/{name}\"\n",
    "            out_path = os.path.join(dest_dir, name)\n",
    "            Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "            rr = requests.get(file_url, **REQUEST_KW)\n",
    "            if rr.status_code == 200 and rr.content:\n",
    "                with open(out_path, \"wb\") as f:\n",
    "                    f.write(rr.content)\n",
    "                saved.append(out_path)\n",
    "            time.sleep(0.2)  # be polite with SEC\n",
    "\n",
    "    if not saved:\n",
    "        raise RuntimeError(\"No XBRL-like files matched in submission directory\")\n",
    "\n",
    "    return {\"mode\": \"files\", \"saved\": saved}\n",
    "\n",
    "\n",
    "# Optional: flatten key statements from sec-api JSON (if PRODUCE_JSON_AND_CSV=True)\n",
    "def extract_financial_statements_for_csv(x: dict) -> List[dict]:\n",
    "    rows: List[dict] = []\n",
    "    for stmt_key in (\"StatementsOfIncome\", \"BalanceSheets\", \"StatementsOfCashFlows\"):\n",
    "        block = x.get(stmt_key)\n",
    "        if isinstance(block, dict):\n",
    "            for concept, facts in block.items():\n",
    "                if isinstance(facts, list):\n",
    "                    for fact in facts:\n",
    "                        if isinstance(fact, dict) and \"value\" in fact:\n",
    "                            rows.append({\n",
    "                                \"statement\": stmt_key,\n",
    "                                \"concept\": concept,\n",
    "                                \"value\": fact.get(\"value\"),\n",
    "                                \"unit\": fact.get(\"unit\"),\n",
    "                                \"period_instant\": (fact.get(\"period\") or {}).get(\"instant\"),\n",
    "                                \"period_start\": (fact.get(\"period\") or {}).get(\"startDate\"),\n",
    "                                \"period_end\": (fact.get(\"period\") or {}).get(\"endDate\"),\n",
    "                                \"segment\": fact.get(\"segment\"),\n",
    "                            })\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Main routine\n",
    "# ==============================\n",
    "def store_xbrl_from_filings(\n",
    "    filings: List[dict],\n",
    "    ticker: str,\n",
    "    cik_str: str,\n",
    "    out_root: str,\n",
    "    also_save_json_csv: bool = False,\n",
    "    xbrl_api_obj: Optional[\"XbrlApi\"] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each filing (expects keys: filedAt, accessionNo, formType),\n",
    "    download and store raw XBRL artifacts to a filing-specific folder.\n",
    "    Optionally, also save JSON + CSV via sec-api xbrl_to_json(accession_no=...).\n",
    "    \"\"\"\n",
    "    print(\"\\nüì¶ Downloading XBRL artifacts from filings...\")\n",
    "    print(f\"üìÇ Output root: {out_root}\")\n",
    "    Path(out_root).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ok = 0\n",
    "    for i, filing in enumerate(filings):\n",
    "        try:\n",
    "            filed_date = str(filing[\"filedAt\"])[:10].replace(\"-\", \"\")\n",
    "            accession_no = filing[\"accessionNo\"]\n",
    "            form_type = filing.get(\"formType\", \"UNKNOWN\")\n",
    "\n",
    "            filing_dir = os.path.join(out_root, f\"{ticker}_{form_type}_{filed_date}_xbrl\")\n",
    "            if os.path.exists(filing_dir) and any(Path(filing_dir).glob(\"*\")):\n",
    "                print(f\"  ‚è© [{i+1}/{len(filings)}] {form_type} {filed_date} already present.\")\n",
    "                ok += 1\n",
    "                continue\n",
    "\n",
    "            print(f\"  üì• [{i+1}/{len(filings)}] {form_type} {filed_date} ‚Üí {filing_dir}\")\n",
    "            res = download_xbrl_zip_or_files(cik_str, accession_no, filing_dir)\n",
    "            print(f\"    ‚úÖ Saved {len(res['saved'])} file(s) via {res['mode']}\")\n",
    "            ok += 1\n",
    "\n",
    "            # Optional: JSON & CSV via sec-api\n",
    "            if also_save_json_csv and xbrl_api_obj:\n",
    "                try:\n",
    "                    xbrl_json = xbrl_api_obj.xbrl_to_json(accession_no=accession_no)\n",
    "                    json_path = os.path.join(filing_dir, f\"{ticker}_{form_type}_{filed_date}_financials.json\")\n",
    "                    with open(json_path, \"w\") as f:\n",
    "                        json.dump(xbrl_json, f, indent=2)\n",
    "\n",
    "                    rows = extract_financial_statements_for_csv(xbrl_json)\n",
    "                    if rows:\n",
    "                        import pandas as pd\n",
    "                        pd.DataFrame(rows).to_csv(\n",
    "                            os.path.join(filing_dir, f\"{ticker}_{form_type}_{filed_date}_financials.csv\"),\n",
    "                            index=False,\n",
    "                        )\n",
    "                    print(\"    üßæ JSON/CSV saved from sec-api xbrl_to_json(accession_no=...)\")\n",
    "                except Exception as je:\n",
    "                    print(f\"    ‚ö†Ô∏è sec-api JSON/CSV step failed: {je}\")\n",
    "\n",
    "            time.sleep(0.5)  # SEC rate-limit courtesy\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ùå Error on filing {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"\\nüìä XBRL Download Summary\")\n",
    "    print(f\"  Total filings: {len(filings)}\")\n",
    "    print(f\"  With XBRL saved: {ok}\")\n",
    "    print(f\"  Success rate: {(ok/len(filings)*100):.1f}%\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Execute if `filings` is available\n",
    "# ==============================\n",
    "if \"filings\" in globals() and isinstance(globals()[\"filings\"], list) and globals()[\"filings\"]:\n",
    "    store_xbrl_from_filings(\n",
    "        filings=filings,\n",
    "        ticker=ticker,\n",
    "        cik_str=cik,\n",
    "        out_root=xbrl_data_dir,\n",
    "        also_save_json_csv=PRODUCE_JSON_AND_CSV,\n",
    "        xbrl_api_obj=xbrl_api,\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è `filings` not found or empty. Provide a list of filing dicts with keys \"\n",
    "          \"filedAt, accessionNo, formType (links optional), then re-run this cell.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
