# ğŸ“„ PDF Parser

**A comprehensive PDF parsing system for extracting structured data from complex financial documents, particularly SEC filings (10-K, 10-Q, etc.).**

This project provides **multi-engine parsing, unified APIs, and quality assessment mechanisms** to process financial documents at scale with high accuracy and reproducibility.

 **GitHub Repo:** [Big-Data-Team-3/pdf-parser](https://github.com/Big-Data-Team-3/pdf-parser.git)
 
- **Interactive Tutorial**: [Google Codelabs - PDF Parser Guide](https://codelabs-preview.appspot.com/?file_id=1aaI--RF5ID99gkCwUVNLQulwxTSsljwvhOqxbY8q3V8#0)

- **Recording Link** : [Video Recording](https://drive.google.com/drive/folders/1ovXMpd7xj6oKaeUFmPXziRpBvTstffFq?usp=drive_link)
---

## ğŸŒŸ Project Description

`pdf_parser` is built to handle the **unique challenges of SEC filings**: complex layouts, nested tables, multi-column text, and scanned documents.

It combines **multiple extraction engines** (rule-based + deep learning + OCR) to ensure reliability, integrates **quality assessment pipelines**, and outputs structured data in formats suitable for downstream analytics.

---

## ğŸ§© Core Features

1. **Text Extraction**

   * Extract clean text using [`pdfplumber`](https://github.com/jsvine/pdfplumber).
   * Preserve **word-level bounding boxes** for layout-aware models.
   * Fallback to **Tesseract OCR** when text extraction fails.

2. **Table Extraction**

   * Detect and parse tables with `pdfplumber` and `tabula`.
   * Preserve table structure & relationships.
   * Export to **CSV/JSON** with page provenance.

3. **Layout & Metadata Capture**

   * Column detection, reading order, and text density analysis.
   * Identify document sections, headings, and form fields.
   * Provenance tracking (URL, accession no., parsing timestamp).

4. **Multi-Engine Architecture**

   * **PDFPlumber** â€“ primary text + tables.
   * **Tabula** â€“ specialized table extraction.
   * **Google Document AI** â€“ cloud-based advanced processing.
   * **Docling** â€“ deep layout analysis & normalization.
   * **Tesseract OCR** â€“ fallback for scanned docs.

5. **Quality Assessment Pipeline**

   * Text quality metrics: word/line counts, density.
   * Confidence scoring (0â€“100) with engine-specific bonuses.
   * Automatic fallback when quality threshold not met.

6. **Structured Data Outputs**

   * JSON / JSONL â€“ structured storage.
   * CSV â€“ tabular data.
   * Markdown â€“ human-readable summaries.
   * TXT â€“ raw extraction.

---

## âš¡ Problem Statement

### **Core Challenges**

* Complex multi-column layouts in SEC filings.
* Need for **multi-modal extraction** (text, tables, forms).
* Maintaining **table structure** across formats.
* Handling poor-quality scans & mixed content types.
* Output flexibility (JSON, TXT, Markdown).

### **Technical Challenges**

* Layout complexity (multi-column, embedded tables, varying fonts).
* OCR fallback for non-text PDFs.
* Scalability for batch document processing.
* Quality assurance across multiple engines.

---

## âœ… Proof of Concept

### 1. Multi-Engine Parsing

* Combines **pdfplumber, tabula, docling, Google Document AI, and Tesseract**.
* Automatic selection of engine based on quality scoring.

### 2. Quality Assessment

* Text density & character distribution checks.
* Confidence scoring for each parsed output.
* OCR fallback when primary methods fail.

### 3. Structured Extraction

* Word-level positioning with bounding boxes.
* Preserved table formatting and relationships.
* Key-value form extraction for structured fields.

---

## ğŸ› ï¸ Technology Stack

### **Primary Layout Understanding**

* **LayoutLMv3** â€“ multimodal transformer for document understanding.
* **LayoutParser** â€“ deep learning layout detection.
* **Docling** â€“ modern document processing.

### **PDF Processing Libraries**

* pdfplumber â€“ text & table extraction.
* tabula â€“ table extraction (Java backend).
* Tesseract â€“ OCR fallback.

### **Version Control & Orchestration**

* **DVC** â€“ pipeline orchestration & metrics.
* **Git + Git-LFS** â€“ versioning & large file storage.

### **Data Formats**

* JSON/JSONL â€“ structured storage.
* CSV â€“ tabular data.
* Markdown â€“ human-readable output.

### **Commercial OCR / Document AI**

* **Google Document AI** â€“ advanced document processing.

---

## ğŸ—ï¸ Architecture

### **Pipeline Flow**

1. **Ingestion** â†’ Download filings (PDF, XBRL) â†’ `data/raw/`.
2. **Preparation** â†’ Convert raw filings into PDFs.
3. **Parsing** â†’ Extract text, tables, and metadata using multiple engines.
4. **Storage** â†’ Save structured outputs (JSON, CSV, Markdown).
5. **Evaluation** â†’ Run quality metrics, cost comparisons, and regression tests.

### **System Architecture**

![SEC EDGAR Document Processing Pipeline](./docs/sec_edgar_final_clean.png)
*SEC EDGAR Document Processing Pipeline â€“ Complete Architecture*


## ğŸš€ Getting Started

### **Prerequisites**

* Python 3.9+
* [Tesseract OCR](https://tesseract-ocr.github.io/) installed
* Java (for Tabula)
* (Optional) GCP for Document AI integration

### **Clone & Setup**

```bash
# Clone repository
git clone https://github.com/Big-Data-Team-3/pdf-parser.git
cd pdf-parser

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### **Run Example**

```bash
# Parse a single PDF
python notebooks/extract_table.py \
    --pdf data/raw/MSFT/10-K/PDFs/MSFT_10-K_20220728.pdf \
    --outdir output_tables
```

---

## ğŸ“‚ Project Structure

```
pdf_parser/
â”œâ”€â”€ docs/                # architecture+schema
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/             # Raw PDFs + XBRL
â”‚   â”œâ”€â”€ parsed/          # Parsed text, tables, metadata
â”œâ”€â”€ notebooks/           # Jupyter notebooks for experiments
â”œâ”€â”€ src/                 # Core parsing modules
â”œâ”€â”€ tests/               # Unit & regression tests
â””â”€â”€ dvc.yml              # Version orchestration
```

---

## ğŸ”— References

* [SEC EDGAR Filings](https://www.sec.gov/edgar.shtml)
* [pdfplumber](https://github.com/jsvine/pdfplumber)
* [Tabula](https://tabula.technology/)
* [DVC](https://dvc.org/)
* [Google Document AI](https://cloud.google.com/document-ai)

---

